# OpenAvatarChat å±å¹•å…±äº«åŠŸèƒ½æŠ€æœ¯æ–¹æ¡ˆ (äº‘æœåŠ¡å™¨TURNç‰ˆ)

## ğŸ“– æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäº**å·²æˆåŠŸéƒ¨ç½²çš„äº‘æœåŠ¡å™¨TURNåŸºç¡€è®¾æ–½**ï¼Œè¯¦ç»†è®¾è®¡OpenAvatarChaté¡¹ç›®ä¸­å±å¹•å…±äº«åŠŸèƒ½çš„å®ç°æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆå……åˆ†åˆ©ç”¨ç°æœ‰çš„é˜¿é‡Œäº‘ECS + coturn TURNæœåŠ¡å™¨æ¶æ„ï¼Œç¡®ä¿å±å¹•å…±äº«åŠŸèƒ½åœ¨å†…ç½‘ç©¿é€ç¯å¢ƒä¸‹å®Œç¾å·¥ä½œã€‚

## ğŸ¯ åŠŸèƒ½ç›®æ ‡

- **è·¨ç½‘ç»œå±å¹•å…±äº«**ï¼šåŸºäºTURNä¸­ç»§çš„å¯é å±å¹•å…±äº«
- **æ™ºèƒ½å†…å®¹åˆ†æ**ï¼šAIç†è§£å±å¹•å†…å®¹å¹¶æä¾›æ™ºèƒ½å¯¹è¯
- **å¤šæºæ— ç¼åˆ‡æ¢**ï¼šæ‘„åƒå¤´ä¸å±å¹•å…±äº«ä¹‹é—´çš„æµç•…åˆ‡æ¢
- **ç§»åŠ¨ç«¯å‹å¥½**ï¼šä¼˜åŒ–çš„ç§»åŠ¨è®¾å¤‡å±å¹•å…±äº«ä½“éªŒ
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé€‚åº”äº‘æœåŠ¡å™¨å¸¦å®½å’Œå¤„ç†èƒ½åŠ›é™åˆ¶

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„ (åŸºäºç°æœ‰TURNåŸºç¡€è®¾æ–½)

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·è®¾å¤‡ (æ‰‹æœº/ç”µè„‘)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   æ‘„åƒå¤´æ•è·    â”‚ â”‚   å±å¹•æ•è·      â”‚ â”‚   éŸ³é¢‘æ•è·      â”‚ â”‚
â”‚ â”‚ getUserMedia()  â”‚ â”‚getDisplayMedia()â”‚ â”‚   éº¦å…‹é£/ç³»ç»Ÿ   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â–¼ åª’ä½“æµ                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚              WebRTC PeerConnection                      â”‚ â”‚
â”‚ â”‚    RTCConfiguration: {                                  â”‚ â”‚
â”‚ â”‚      iceServers: [                                      â”‚ â”‚
â”‚ â”‚        "stun:stun.l.google.com:19302",                 â”‚ â”‚
â”‚ â”‚        "turn:8.138.87.249:3478"  // æ‚¨çš„TURNæœåŠ¡å™¨      â”‚ â”‚
â”‚ â”‚      ]                                                  â”‚ â”‚
â”‚ â”‚    }                                                    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ WebRTCä¿¡ä»¤ (HTTP/HTTPS)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å†…ç½‘ç©¿é€æœåŠ¡                               â”‚
â”‚              https://liao.uunat.com:8282                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ TCP 8282ç«¯å£
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 æœ¬åœ°OpenAvatarChatæœåŠ¡                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ WebRTCä¿¡ä»¤å¤„ç†                                            â”‚
â”‚ â€¢ å±å¹•å¸§æ¥æ”¶å’Œåˆ†æ                                          â”‚
â”‚ â€¢ OCRæ–‡å­—è¯†åˆ«                                              â”‚
â”‚ â€¢ AIå†…å®¹ç†è§£ (MiniCPM-o/Qwen-Omni)                        â”‚
â”‚ â€¢ æ•°å­—äººè§†é¢‘ç”Ÿæˆ                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚ WebRTCåª’ä½“æµ (UDP)
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              äº‘æœåŠ¡å™¨TURNä¸­ç»§ (å·²éƒ¨ç½²æˆåŠŸ)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŒ å…¬ç½‘IP: 8.138.87.249                                    â”‚
â”‚ ğŸ”§ å†…ç½‘IP: 172.18.57.220                                   â”‚
â”‚                                                             â”‚
â”‚ âœ… TCP 3478ç«¯å£ (TURNæ§åˆ¶)                                  â”‚
â”‚ âœ… UDP 3478ç«¯å£ (TURNæ•°æ®)                                  â”‚
â”‚ âœ… UDP 49152-65535 (åª’ä½“ä¸­ç»§)                               â”‚
â”‚                                                             â”‚
â”‚ ğŸ“Š éªŒè¯çŠ¶æ€: 13é¡¹æ£€æŸ¥å…¨é€šè¿‡                                  â”‚
â”‚ ğŸ† coturnè¿›ç¨‹: âœ… ç›‘å¬0.0.0.0:3478                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµè¯¦è§£

1. **ä¿¡ä»¤æµ (HTTP/HTTPS)**ï¼š
   ```
   å®¢æˆ·ç«¯ â†’ å†…ç½‘ç©¿é€ â†’ æœ¬åœ°æœåŠ¡å™¨ (WebRTC Offer/Answer)
   ```

2. **åª’ä½“æµ (UDPé€šè¿‡TURNä¸­ç»§)**ï¼š
   ```
   å®¢æˆ·ç«¯ â†” äº‘æœåŠ¡å™¨TURN â†” æœ¬åœ°æœåŠ¡å™¨ (å±å¹•/éŸ³é¢‘æ•°æ®)
```

---

## ğŸ”§ æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### 1. å‰ç«¯å±å¹•æ•è·å®ç°

#### 1.1 TURNä¼˜åŒ–çš„å±å¹•æ•è·

```typescript
// src/handlers/client/rtc_client/frontend/src/utils/screenShareUtils.ts

export interface TurnOptimizedScreenShareOptions {
  video: boolean | MediaTrackConstraints;
  audio: boolean | MediaTrackConstraints;
  displaySurface?: 'browser' | 'window' | 'monitor';
  quality: 'mobile' | 'desktop' | 'high-bandwidth';
  turnOptimized: boolean;
}

/**
 * åŸºäºTURNæœåŠ¡å™¨çš„å±å¹•å…±äº«é…ç½®
 * é’ˆå¯¹äº‘æœåŠ¡å™¨å¸¦å®½å’Œæ€§èƒ½ä¼˜åŒ–
 */
const TURN_SERVER_CONFIG: RTCConfiguration = {
  iceServers: [
    { urls: "stun:stun.l.google.com:19302" },
    { urls: "stun:stun1.l.google.com:19302" },
    { 
      urls: "turn:8.138.87.249:3478",
      username: "username",
      credential: "password"
    }
  ],
  iceCandidatePoolSize: 10,
  iceTransportPolicy: 'all',  // å…è®¸P2På’ŒTURN
  bundlePolicy: 'balanced',
  rtcpMuxPolicy: 'require'
};

/**
 * äº‘æœåŠ¡å™¨ä¼˜åŒ–çš„è´¨é‡é…ç½®
 * åŸºäº1æ ¸2Gäº‘æœåŠ¡å™¨èƒ½åŠ›è°ƒæ•´
 */
const QUALITY_PRESETS = {
  mobile: {
    video: {
      width: { ideal: 720, max: 960 },
      height: { ideal: 480, max: 640 },
      frameRate: { ideal: 8, max: 12 },
      cursor: 'always',
      displaySurface: 'window'  // ä¼˜å…ˆçª—å£ï¼Œå‡å°‘æ•°æ®é‡
    },
    audio: {
          echoCancellation: true,
          noiseSuppression: true,
      autoGainControl: true,
      systemAudio: false  // ç§»åŠ¨ç«¯é€šå¸¸ä¸æ”¯æŒ
    }
  },
  desktop: {
    video: {
      width: { ideal: 1280, max: 1600 },
      height: { ideal: 720, max: 900 },
      frameRate: { ideal: 15, max: 20 },  // ä½å¸§ç‡å‡å°‘å¸¦å®½
      cursor: 'always',
      displaySurface: 'monitor'
    },
    audio: {
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true,
      systemAudio: true  // æ¡Œé¢æ”¯æŒç³»ç»ŸéŸ³é¢‘
    }
  },
  'high-bandwidth': {
    video: {
      width: { ideal: 1920, max: 2560 },
      height: { ideal: 1080, max: 1440 },
      frameRate: { ideal: 15, max: 24 },
      cursor: 'always',
      displaySurface: 'monitor'
    },
    audio: {
      echoCancellation: true,
      noiseSuppression: true,
      systemAudio: true
    }
  }
};

/**
 * è·å–TURNä¼˜åŒ–çš„å±å¹•å…±äº«æµ
 */
export async function getTurnOptimizedDisplayStream(
  options: TurnOptimizedScreenShareOptions
): Promise<MediaStream> {
  
  // æ ¹æ®è®¾å¤‡ç±»å‹è‡ªåŠ¨é€‰æ‹©è´¨é‡
  const deviceType = detectDeviceType();
  const qualityPreset = options.quality || (deviceType === 'mobile' ? 'mobile' : 'desktop');
  
  const constraints: DisplayMediaStreamConstraints = {
    video: typeof options.video === 'object' 
      ? { ...QUALITY_PRESETS[qualityPreset].video, ...options.video }
      : QUALITY_PRESETS[qualityPreset].video,
    audio: typeof options.audio === 'object'
      ? { ...QUALITY_PRESETS[qualityPreset].audio, ...options.audio }
      : QUALITY_PRESETS[qualityPreset].audio
  };

  try {
    console.log('ğŸš€ å¼€å§‹å±å¹•æ•è·ï¼Œè´¨é‡é¢„è®¾:', qualityPreset);
    console.log('ğŸ“Š çº¦æŸé…ç½®:', constraints);
    
    const displayStream = await navigator.mediaDevices.getDisplayMedia(constraints);
    
    // ç›‘å¬ç”¨æˆ·åœæ­¢å…±äº«äº‹ä»¶
    displayStream.getVideoTracks()[0].addEventListener('ended', () => {
      console.log('ğŸ›‘ ç”¨æˆ·åœæ­¢å±å¹•å…±äº«');
      // è§¦å‘çŠ¶æ€æ›´æ–°äº‹ä»¶
      window.dispatchEvent(new CustomEvent('screenShareEnded'));
    });
    
    // ç›‘å¬è½¨é“è®¾ç½®å˜åŒ–
    displayStream.getVideoTracks()[0].addEventListener('settingschange', () => {
      const settings = displayStream.getVideoTracks()[0].getSettings();
      console.log('âš™ï¸ å±å¹•å…±äº«è®¾ç½®å˜åŒ–:', settings);
    });
    
    return displayStream;
  } catch (error) {
    console.error('âŒ å±å¹•æ•è·å¤±è´¥:', error);
    throw new ScreenShareError('å±å¹•æ•è·å¤±è´¥', error);
  }
}

/**
 * æ£€æµ‹è®¾å¤‡ç±»å‹
 */
function detectDeviceType(): 'mobile' | 'tablet' | 'desktop' {
  const userAgent = navigator.userAgent;
  
  if (/Android|iPhone|iPod/.test(userAgent)) {
    return 'mobile';
  } else if (/iPad/.test(userAgent)) {
    return 'tablet';  
  } else {
    return 'desktop';
  }
}

/**
 * å±å¹•å…±äº«é”™è¯¯ç±»
 */
class ScreenShareError extends Error {
  constructor(message: string, public originalError?: Error) {
    super(message);
    this.name = 'ScreenShareError';
  }
}

/**
 * TURNè¿æ¥è´¨é‡ç›‘æ§
 */
export class TurnConnectionMonitor {
  private peerConnection: RTCPeerConnection | null = null;
  private qualityCheckInterval: number | null = null;
  private onQualityChange?: (quality: ConnectionQuality) => void;
  
  constructor(pc: RTCPeerConnection, callback?: (quality: ConnectionQuality) => void) {
    this.peerConnection = pc;
    this.onQualityChange = callback;
    this.startMonitoring();
  }
  
  private startMonitoring() {
    this.qualityCheckInterval = window.setInterval(() => {
      this.checkConnectionQuality();
    }, 2000);  // æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
  }
  
  private async checkConnectionQuality() {
    if (!this.peerConnection) return;
    
    try {
      const stats = await this.peerConnection.getStats();
      const quality = this.analyzeStats(stats);
      
      if (this.onQualityChange) {
        this.onQualityChange(quality);
      }
    } catch (error) {
      console.error('è¿æ¥è´¨é‡æ£€æŸ¥å¤±è´¥:', error);
    }
  }
  
  private analyzeStats(stats: RTCStatsReport): ConnectionQuality {
    let bytesReceived = 0;
    let bytesSent = 0;
    let packetsLost = 0;
    let rtt = 0;
    
    stats.forEach((report) => {
      if (report.type === 'inbound-rtp' && report.kind === 'video') {
        bytesReceived += report.bytesReceived || 0;
        packetsLost += report.packetsLost || 0;
      }
      if (report.type === 'outbound-rtp' && report.kind === 'video') {
        bytesSent += report.bytesSent || 0;
      }
      if (report.type === 'remote-inbound-rtp' && report.kind === 'video') {
        rtt = report.roundTripTime || 0;
      }
    });
    
    // è®¡ç®—è´¨é‡ç­‰çº§
    const bandwidth = (bytesReceived + bytesSent) / 1024; // KB/s
    const packetLossRate = packetsLost / (packetsLost + 100); // ç®€åŒ–è®¡ç®—
    
    if (bandwidth > 500 && rtt < 100 && packetLossRate < 0.01) {
      return 'excellent';
    } else if (bandwidth > 200 && rtt < 200 && packetLossRate < 0.05) {
      return 'good';
    } else if (bandwidth > 50 && rtt < 500) {
      return 'fair';
    } else {
      return 'poor';
    }
  }
  
  stopMonitoring() {
    if (this.qualityCheckInterval) {
      clearInterval(this.qualityCheckInterval);
      this.qualityCheckInterval = null;
    }
  }
}

type ConnectionQuality = 'excellent' | 'good' | 'fair' | 'poor';
```

#### 1.2 Vueç»„ä»¶çŠ¶æ€ç®¡ç†å¢å¼º

```typescript
// src/handlers/client/rtc_client/frontend/src/store/screenShareStore.ts

import { defineStore } from 'pinia';
import { ref, computed } from 'vue';
import { 
  getTurnOptimizedDisplayStream, 
  TurnConnectionMonitor,
  TURN_SERVER_CONFIG 
} from '@/utils/screenShareUtils';

interface ScreenShareState {
  // åŸºç¡€çŠ¶æ€
  isScreenSharing: boolean;
  screenShareStream: MediaStream | null;
  screenShareSupported: boolean;
  currentVideoSource: 'camera' | 'screen';
  
  // TURNè¿æ¥çŠ¶æ€
  turnConnectionState: RTCIceConnectionState;
  turnConnectionQuality: 'excellent' | 'good' | 'fair' | 'poor';
  iceGatheringState: RTCIceGatheringState;
  
  // æ€§èƒ½ç›‘æ§
  connectionStats: {
    bytesReceived: number;
    bytesSent: number;
    packetsLost: number;
    roundTripTime: number;
    bandwidth: number;
  };
  
  // ç”¨æˆ·é€‰é¡¹
  screenShareOptions: {
    quality: 'mobile' | 'desktop' | 'high-bandwidth';
    includeSystemAudio: boolean;
    captureMode: 'desktop' | 'window' | 'tab';
    autoQualityAdjust: boolean;
  };
}

export const useScreenShareStore = defineStore('screenShare', () => {
  // å“åº”å¼çŠ¶æ€
  const state = ref<ScreenShareState>({
    isScreenSharing: false,
    screenShareStream: null,
    screenShareSupported: false,
    currentVideoSource: 'camera',
    
    turnConnectionState: 'new',
    turnConnectionQuality: 'good',
    iceGatheringState: 'new',
    
    connectionStats: {
      bytesReceived: 0,
      bytesSent: 0,
      packetsLost: 0,
      roundTripTime: 0,
      bandwidth: 0
    },
    
    screenShareOptions: {
      quality: 'desktop',
      includeSystemAudio: false,
      captureMode: 'window',
      autoQualityAdjust: true
    }
  });
  
  // è®¡ç®—å±æ€§
  const isConnected = computed(() => 
    state.value.turnConnectionState === 'connected'
  );
  
  const shouldOptimizeQuality = computed(() => 
    state.value.turnConnectionQuality === 'poor' || 
    state.value.turnConnectionQuality === 'fair'
  );
  
  // WebRTCç›¸å…³å®ä¾‹
  let peerConnection: RTCPeerConnection | null = null;
  let connectionMonitor: TurnConnectionMonitor | null = null;
    
    /**
     * åˆå§‹åŒ–å±å¹•å…±äº«åŠŸèƒ½
     */
  async function initializeScreenShare() {
    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    state.value.screenShareSupported = !!(
      navigator.mediaDevices && 
      navigator.mediaDevices.getDisplayMedia
    );
    
    if (!state.value.screenShareSupported) {
      console.warn('âš ï¸ å½“å‰æµè§ˆå™¨ä¸æ”¯æŒå±å¹•å…±äº«');
      return false;
    }
    
    // åˆå§‹åŒ–WebRTCè¿æ¥
    try {
      peerConnection = new RTCPeerConnection(TURN_SERVER_CONFIG);
      setupPeerConnectionEvents();
      console.log('âœ… WebRTC PeerConnectionåˆå§‹åŒ–æˆåŠŸ');
      return true;
    } catch (error) {
      console.error('âŒ WebRTCåˆå§‹åŒ–å¤±è´¥:', error);
      return false;
    }
  }
  
  /**
   * è®¾ç½®PeerConnectionäº‹ä»¶ç›‘å¬
   */
  function setupPeerConnectionEvents() {
    if (!peerConnection) return;
    
    // ICEè¿æ¥çŠ¶æ€å˜åŒ–
    peerConnection.addEventListener('iceconnectionstatechange', () => {
      state.value.turnConnectionState = peerConnection!.iceConnectionState;
      console.log('ğŸ”— ICEè¿æ¥çŠ¶æ€:', state.value.turnConnectionState);
    });
    
    // ICEæ”¶é›†çŠ¶æ€å˜åŒ–
    peerConnection.addEventListener('icegatheringstatechange', () => {
      state.value.iceGatheringState = peerConnection!.iceGatheringState;
      console.log('ğŸ“¡ ICEæ”¶é›†çŠ¶æ€:', state.value.iceGatheringState);
    });
    
    // ICEå€™é€‰è€…
    peerConnection.addEventListener('icecandidate', (event) => {
      if (event.candidate) {
        console.log('ğŸ§Š ICEå€™é€‰è€…:', {
          type: event.candidate.type,
          protocol: event.candidate.protocol,
          address: event.candidate.address
        });
      }
    });
  }

    /**
     * å¼€å§‹å±å¹•å…±äº«
     */
  async function startScreenShare() {
    if (!state.value.screenShareSupported) {
      throw new Error('æµè§ˆå™¨ä¸æ”¯æŒå±å¹•å…±äº«');
    }
    
    if (state.value.isScreenSharing) {
      console.log('âš ï¸ å±å¹•å…±äº«å·²ç»åœ¨è¿›è¡Œä¸­');
      return;
      }

      try {
      console.log('ğŸš€ å¼€å§‹å±å¹•å…±äº«...');
      
      // è·å–å±å¹•å…±äº«æµ
      const displayStream = await getTurnOptimizedDisplayStream({
        video: true,
        audio: state.value.screenShareOptions.includeSystemAudio,
        quality: state.value.screenShareOptions.quality,
        turnOptimized: true
      });
      
      // æ›´æ–°çŠ¶æ€
      state.value.screenShareStream = displayStream;
      state.value.isScreenSharing = true;
      state.value.currentVideoSource = 'screen';
      
      // å°†æµæ·»åŠ åˆ°PeerConnection
      if (peerConnection) {
        displayStream.getTracks().forEach(track => {
          peerConnection!.addTrack(track, displayStream);
        });
      }
      
      // å¯åŠ¨è¿æ¥è´¨é‡ç›‘æ§
      if (peerConnection) {
        connectionMonitor = new TurnConnectionMonitor(
          peerConnection,
          (quality) => {
            state.value.turnConnectionQuality = quality;
            
            // è‡ªåŠ¨è´¨é‡è°ƒæ•´
            if (state.value.screenShareOptions.autoQualityAdjust && quality === 'poor') {
              console.log('ğŸ“‰ è¿æ¥è´¨é‡å·®ï¼Œè‡ªåŠ¨é™ä½è´¨é‡');
              adjustQualityForPoorConnection();
            }
          }
        );
      }
      
      console.log('âœ… å±å¹•å…±äº«å¯åŠ¨æˆåŠŸ');

      } catch (error) {
      console.error('âŒ å±å¹•å…±äº«å¯åŠ¨å¤±è´¥:', error);
      
      // æ¸…ç†çŠ¶æ€
      state.value.isScreenSharing = false;
      state.value.screenShareStream = null;
      state.value.currentVideoSource = 'camera';
      
        throw error;
      }
  }
  
  /**
   * åœæ­¢å±å¹•å…±äº«
   */
  async function stopScreenShare() {
    if (!state.value.isScreenSharing) {
      console.log('âš ï¸ å±å¹•å…±äº«æœªåœ¨è¿›è¡Œä¸­');
      return;
    }
    
    try {
      console.log('ğŸ›‘ åœæ­¢å±å¹•å…±äº«...');
      
      // åœæ­¢æµ
      if (state.value.screenShareStream) {
        state.value.screenShareStream.getTracks().forEach(track => {
          track.stop();
        });
      }
      
      // åœæ­¢è¿æ¥ç›‘æ§
      if (connectionMonitor) {
        connectionMonitor.stopMonitoring();
        connectionMonitor = null;
      }
      
      // æ›´æ–°çŠ¶æ€
      state.value.screenShareStream = null;
      state.value.isScreenSharing = false;
      state.value.currentVideoSource = 'camera';
      
      console.log('âœ… å±å¹•å…±äº«å·²åœæ­¢');

      } catch (error) {
      console.error('âŒ åœæ­¢å±å¹•å…±äº«å¤±è´¥:', error);
        throw error;
      }
  }
  
  /**
   * è¿æ¥è´¨é‡å·®æ—¶è‡ªåŠ¨è°ƒæ•´
   */
  function adjustQualityForPoorConnection() {
    const currentQuality = state.value.screenShareOptions.quality;
    
    if (currentQuality === 'high-bandwidth') {
      state.value.screenShareOptions.quality = 'desktop';
    } else if (currentQuality === 'desktop') {
      state.value.screenShareOptions.quality = 'mobile';
    }
    // mobileå·²ç»æ˜¯æœ€ä½è´¨é‡ï¼Œä¸å†é™ä½
    
    console.log(`ğŸ“Š è´¨é‡å·²è°ƒæ•´ä¸º: ${state.value.screenShareOptions.quality}`);
  }
  
  /**
   * åˆ‡æ¢å±å¹•å…±äº«çŠ¶æ€
   */
  async function toggleScreenShare() {
    if (state.value.isScreenSharing) {
      await stopScreenShare();
    } else {
      await startScreenShare();
    }
  }
  
  /**
   * æ›´æ–°å±å¹•å…±äº«é€‰é¡¹
   */
  function updateScreenShareOptions(options: Partial<typeof state.value.screenShareOptions>) {
    state.value.screenShareOptions = {
      ...state.value.screenShareOptions,
      ...options
    };
    
    console.log('âš™ï¸ å±å¹•å…±äº«é€‰é¡¹å·²æ›´æ–°:', state.value.screenShareOptions);
  }
  
  return {
    // çŠ¶æ€
    state: readonly(state),
    
    // è®¡ç®—å±æ€§
    isConnected,
    shouldOptimizeQuality,
    
    // æ–¹æ³•
    initializeScreenShare,
    startScreenShare,
    stopScreenShare,
    toggleScreenShare,
    updateScreenShareOptions
  };
});
```

### 2. å±å¹•å…±äº«æ§åˆ¶ç»„ä»¶

```vue
<!-- src/handlers/client/rtc_client/frontend/src/components/ScreenShareControl.vue -->

<template>
  <div class="screen-share-control">
    <!-- ä¸»æ§åˆ¶æŒ‰é’® -->
    <div class="main-controls">
    <button
      v-if="screenShareSupported"
        @click="handleToggleScreenShare"
        :class="[
          'screen-share-btn',
          {
        'active': isScreenSharing,
            'connecting': turnConnectionState === 'checking',
            'disabled': !canToggle
          }
        ]"
        :disabled="!canToggle"
      >
        <Icon 
          :name="getButtonIcon" 
          :class="{ 'spin': turnConnectionState === 'checking' }"
        />
        <span>{{ getButtonText }}</span>
    </button>

      <div v-else class="unsupported-notice">
        <Icon name="warning" />
        <span>å½“å‰æµè§ˆå™¨ä¸æ”¯æŒå±å¹•å…±äº«</span>
      </div>
    </div>

    <!-- è¿æ¥çŠ¶æ€æŒ‡ç¤ºå™¨ -->
    <div v-if="isScreenSharing" class="connection-status">
      <div class="status-row">
        <div class="status-indicator" :class="connectionStatusClass">
          <div class="indicator-dot"></div>
          <span>{{ connectionStatusText }}</span>
        </div>
        
        <div class="quality-indicator" :class="`quality-${turnConnectionQuality}`">
          <span>{{ qualityText }}</span>
        </div>
      </div>
      
      <!-- è¿æ¥ç»Ÿè®¡ -->
      <div v-if="showStats" class="connection-stats">
        <div class="stat-item">
          <label>å¸¦å®½:</label>
          <span>{{ formatBandwidth(connectionStats.bandwidth) }}</span>
        </div>
        <div class="stat-item">
          <label>å»¶è¿Ÿ:</label>
          <span>{{ connectionStats.roundTripTime }}ms</span>
        </div>
        <div class="stat-item">
          <label>ä¸¢åŒ…:</label>
          <span>{{ connectionStats.packetsLost }}</span>
        </div>
      </div>
    </div>

    <!-- è®¾ç½®é¢æ¿ -->
    <div v-if="showSettings" class="settings-panel">
      <div class="setting-group">
        <label>è´¨é‡è®¾ç½®:</label>
        <select 
          v-model="localOptions.quality"
          @change="updateOptions"
          :disabled="isScreenSharing"
        >
          <option value="mobile">ç§»åŠ¨ä¼˜åŒ– (720p@8fps)</option>
          <option value="desktop">æ¡Œé¢æ ‡å‡† (1080p@10fps)</option>
          <option value="high-bandwidth">é«˜è´¨é‡ (1080p@15fps)</option>
        </select>
        <small class="quality-hint">{{ getQualityHint(localOptions.quality) }}</small>
      </div>

      <div class="setting-group">
        <label>æ•è·æ¨¡å¼:</label>
        <select 
          v-model="localOptions.captureMode"
          @change="updateOptions"
          :disabled="isScreenSharing"
        >
          <option value="window">åº”ç”¨ç¨‹åºçª—å£</option>
          <option value="desktop">æ•´ä¸ªæ¡Œé¢</option>
          <option value="tab">æµè§ˆå™¨æ ‡ç­¾é¡µ</option>
        </select>
      </div>

      <div class="setting-group">
        <label class="checkbox-label">
          <input 
            type="checkbox" 
            v-model="localOptions.includeSystemAudio"
            @change="updateOptions"
            :disabled="isScreenSharing || isMobile"
          />
          <span>åŒ…å«ç³»ç»ŸéŸ³é¢‘</span>
          <small v-if="isMobile" class="disabled-note">(ç§»åŠ¨ç«¯ä¸æ”¯æŒ)</small>
        </label>
      </div>

      <div class="setting-group">
        <label class="checkbox-label">
          <input 
            type="checkbox" 
            v-model="localOptions.autoQualityAdjust"
            @change="updateOptions"
          />
          <span>è‡ªåŠ¨è´¨é‡è°ƒæ•´</span>
          <small>æ ¹æ®ç½‘ç»œçŠ¶å†µè‡ªåŠ¨é™ä½è´¨é‡</small>
        </label>
      </div>
    </div>

    <!-- æ“ä½œæŒ‰é’® -->
    <div class="action-buttons">
      <button 
        @click="showSettings = !showSettings"
        class="settings-btn"
        :class="{ active: showSettings }"
      >
        <Icon name="settings" />
        è®¾ç½®
      </button>
      
      <button 
        @click="showStats = !showStats"
        class="stats-btn"
        :class="{ active: showStats }"
        v-if="isScreenSharing"
      >
        <Icon name="chart" />
        ç»Ÿè®¡
      </button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { computed, ref, reactive, onMounted, onUnmounted } from 'vue';
import { useScreenShareStore } from '@/store/screenShareStore';
import { message } from 'ant-design-vue';

const screenShareStore = useScreenShareStore();

// æœ¬åœ°çŠ¶æ€
const showSettings = ref(false);
const showStats = ref(false);
const localOptions = reactive({
  quality: 'desktop',
  captureMode: 'window',
  includeSystemAudio: false,
  autoQualityAdjust: true
});

// è®¡ç®—å±æ€§
const screenShareSupported = computed(() => screenShareStore.state.screenShareSupported);
const isScreenSharing = computed(() => screenShareStore.state.isScreenSharing);
const turnConnectionState = computed(() => screenShareStore.state.turnConnectionState);
const turnConnectionQuality = computed(() => screenShareStore.state.turnConnectionQuality);
const connectionStats = computed(() => screenShareStore.state.connectionStats);

const canToggle = computed(() => {
  return screenShareSupported.value && 
         (turnConnectionState.value !== 'checking');
});

const isMobile = computed(() => {
  return /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i
    .test(navigator.userAgent);
});

const getButtonIcon = computed(() => {
  if (turnConnectionState.value === 'checking') return 'loading';
  if (isScreenSharing.value) return 'screen-share-stop';
  return 'screen-share';
});

const getButtonText = computed(() => {
  if (turnConnectionState.value === 'checking') return 'è¿æ¥ä¸­...';
  if (isScreenSharing.value) return 'åœæ­¢å…±äº«';
  return 'å…±äº«å±å¹•';
});

const connectionStatusClass = computed(() => {
  switch (turnConnectionState.value) {
    case 'connected': return 'status-connected';
    case 'checking': return 'status-connecting';
    case 'disconnected': return 'status-disconnected';
    case 'failed': return 'status-failed';
    default: return 'status-new';
  }
});

const connectionStatusText = computed(() => {
  switch (turnConnectionState.value) {
    case 'connected': return 'å·²è¿æ¥åˆ°TURNæœåŠ¡å™¨';
    case 'checking': return 'æ­£åœ¨è¿æ¥TURNæœåŠ¡å™¨...';
    case 'disconnected': return 'TURNè¿æ¥æ–­å¼€';
    case 'failed': return 'TURNè¿æ¥å¤±è´¥';
    default: return 'å‡†å¤‡å°±ç»ª';
  }
});

const qualityText = computed(() => {
  switch (turnConnectionQuality.value) {
    case 'excellent': return 'ä¼˜ç§€';
    case 'good': return 'è‰¯å¥½';
    case 'fair': return 'ä¸€èˆ¬';
    case 'poor': return 'è¾ƒå·®';
    default: return 'æœªçŸ¥';
  }
});

// æ–¹æ³•
async function handleToggleScreenShare() {
  try {
    await screenShareStore.toggleScreenShare();
    
    if (isScreenSharing.value) {
      message.success('å±å¹•å…±äº«å·²å¼€å§‹');
    } else {
      message.success('å±å¹•å…±äº«å·²åœæ­¢');
    }
  } catch (error) {
    console.error('å±å¹•å…±äº«åˆ‡æ¢å¤±è´¥:', error);
    message.error(
      isScreenSharing.value 
        ? 'åœæ­¢å±å¹•å…±äº«å¤±è´¥' 
        : 'å¼€å§‹å±å¹•å…±äº«å¤±è´¥'
    );
  }
}

function updateOptions() {
  screenShareStore.updateScreenShareOptions(localOptions);
}

function getQualityHint(quality: string): string {
  switch (quality) {
    case 'mobile':
      return 'é€‚ç”¨äºç§»åŠ¨ç½‘ç»œï¼Œä½å¸¦å®½æ¶ˆè€—';
    case 'desktop':
      return 'å¹³è¡¡è´¨é‡ä¸æ€§èƒ½ï¼Œæ¨èé€‰æ‹©';
    case 'high-bandwidth':
      return 'é«˜è´¨é‡ï¼Œéœ€è¦è‰¯å¥½ç½‘ç»œç¯å¢ƒ';
    default:
      return '';
  }
}

function formatBandwidth(bytes: number): string {
  if (bytes < 1024) return `${bytes} B/s`;
  if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB/s`;
  return `${(bytes / 1024 / 1024).toFixed(2)} MB/s`;
}

// ç”Ÿå‘½å‘¨æœŸ
onMounted(async () => {
  // åˆå§‹åŒ–å±å¹•å…±äº«åŠŸèƒ½
  await screenShareStore.initializeScreenShare();
  
  // åŒæ­¥é€‰é¡¹
  Object.assign(localOptions, screenShareStore.state.screenShareOptions);
});

onUnmounted(() => {
  // ç»„ä»¶é”€æ¯æ—¶åœæ­¢å±å¹•å…±äº«
  if (isScreenSharing.value) {
    screenShareStore.stopScreenShare();
  }
});
</script>

<style scoped lang="less">
.screen-share-control {
  padding: 16px;
  border: 1px solid #e8e8e8;
  border-radius: 8px;
  background: white;
  
  .main-controls {
    margin-bottom: 12px;
    
  .screen-share-btn {
    display: flex;
    align-items: center;
    gap: 8px;
      padding: 12px 20px;
      border: 2px solid #d9d9d9;
      border-radius: 8px;
    background: white;
      font-size: 14px;
      font-weight: 500;
    cursor: pointer;
      transition: all 0.3s ease;

    &:hover:not(.disabled) {
      border-color: #1890ff;
      background: #f0f7ff;
        transform: translateY(-1px);
    }

    &.active {
      background: #1890ff;
      color: white;
      border-color: #1890ff;
        
        &:hover {
          background: #40a9ff;
        }
      }
      
      &.connecting {
        border-color: #faad14;
        background: #fff7e6;
        color: #d46b08;
        
        .spin {
          animation: spin 1s linear infinite;
        }
    }

    &.disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
  }

    .unsupported-notice {
      display: flex;
      align-items: center;
      gap: 8px;
    padding: 12px;
      background: #fff2e8;
      border: 1px solid #ffbb96;
    border-radius: 6px;
      color: #d4380d;
      font-size: 13px;
    }
  }
  
  .connection-status {
    margin-bottom: 16px;
    padding: 12px;
    background: #fafafa;
    border-radius: 6px;

    .status-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 8px;
    }
    
    .status-indicator {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 13px;
      
      .indicator-dot {
        width: 8px;
        height: 8px;
        border-radius: 50%;
        
        .status-connected & {
          background: #52c41a;
          animation: pulse 2s infinite;
        }
        
        .status-connecting & {
          background: #faad14;
          animation: blink 1s infinite;
        }
        
        .status-disconnected & {
          background: #d9d9d9;
        }
        
        .status-failed & {
          background: #ff4d4f;
        }
      }
      
      &.status-connected { color: #389e0d; }
      &.status-connecting { color: #d46b08; }
      &.status-disconnected { color: #8c8c8c; }
      &.status-failed { color: #cf1322; }
    }
    
    .quality-indicator {
      font-size: 12px;
      padding: 2px 8px;
      border-radius: 12px;
      
      &.quality-excellent {
        background: #f6ffed;
        color: #389e0d;
        border: 1px solid #b7eb8f;
      }
      
      &.quality-good {
        background: #f0f7ff;
        color: #1890ff;
        border: 1px solid #91d5ff;
      }
      
      &.quality-fair {
        background: #fff7e6;
        color: #d46b08;
        border: 1px solid #ffd591;
      }
      
      &.quality-poor {
        background: #fff2f0;
        color: #cf1322;
        border: 1px solid #ffccc7;
      }
    }
    
    .connection-stats {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 12px;
      margin-top: 8px;
      
      .stat-item {
        text-align: center;

      label {
          display: block;
          font-size: 11px;
          color: #8c8c8c;
          margin-bottom: 2px;
        }
        
        span {
          display: block;
          font-size: 12px;
          font-weight: 600;
          color: #262626;
        }
      }
    }
  }
  
  .settings-panel {
    margin-bottom: 16px;
    padding: 16px;
    background: #fafafa;
    border-radius: 6px;
    
    .setting-group {
      margin-bottom: 16px;
      
      &:last-child {
        margin-bottom: 0;
      }
      
      label {
        display: block;
        font-size: 13px;
        font-weight: 500;
        color: #262626;
        margin-bottom: 6px;
        
        &.checkbox-label {
          display: flex;
          align-items: flex-start;
          gap: 8px;
          cursor: pointer;
          
          input[type="checkbox"] {
            margin-top: 2px;
          }
          
          span {
            flex: 1;
          }
        }
      }
      
      select {
        width: 100%;
        padding: 6px 12px;
        border: 1px solid #d9d9d9;
        border-radius: 4px;
        font-size: 13px;
        
        &:focus {
          border-color: #1890ff;
          box-shadow: 0 0 0 2px rgba(24, 144, 255, 0.2);
          outline: none;
        }
        
        &:disabled {
          background: #f5f5f5;
          color: #bfbfbf;
        }
      }
      
      small {
        display: block;
        font-size: 11px;
        color: #8c8c8c;
        margin-top: 4px;
        
        &.quality-hint {
          color: #1890ff;
        }
        
        &.disabled-note {
          color: #cf1322;
        }
      }
    }
  }
  
  .action-buttons {
    display: flex;
    gap: 8px;
    
    button {
      display: flex;
      align-items: center;
      gap: 4px;
    padding: 6px 12px;
      border: 1px solid #d9d9d9;
    border-radius: 4px;
      background: white;
    font-size: 12px;
      cursor: pointer;
      transition: all 0.2s;
      
      &:hover {
        border-color: #1890ff;
        color: #1890ff;
      }
      
      &.active {
        background: #1890ff;
        color: white;
        border-color: #1890ff;
      }
    }
  }
}

@keyframes spin {
  from { transform: rotate(0deg); }
  to { transform: rotate(360deg); }
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.5; }
}

@keyframes blink {
  0%, 50% { opacity: 1; }
  51%, 100% { opacity: 0.3; }
}
</style>
```

### 3. åç«¯å±å¹•å†…å®¹åˆ†æå¢å¼º

```python
# src/handlers/llm/screen_content_analyzer.py

import asyncio
import hashlib
from typing import Optional, List, Dict, Any, Tuple
import cv2
import numpy as np
from PIL import Image, ImageEnhance
import pytesseract
from loguru import logger
import time

class CloudOptimizedScreenAnalyzer:
    """
    äº‘æœåŠ¡å™¨ä¼˜åŒ–çš„å±å¹•å†…å®¹åˆ†æå™¨
    åŸºäº1æ ¸2Gäº‘æœåŠ¡å™¨èµ„æºé™åˆ¶ä¼˜åŒ–
    """
    
    def __init__(self, 
                 ocr_enabled: bool = True,
                 max_analysis_fps: float = 0.5,  # æ¯2ç§’åˆ†æä¸€æ¬¡
                 frame_resize_factor: float = 0.5):  # ç¼©æ”¾å› å­å‡å°‘è®¡ç®—é‡
        
        self.ocr_enabled = ocr_enabled and self._check_ocr_available()
        self.max_analysis_fps = max_analysis_fps
        self.frame_resize_factor = frame_resize_factor
        
        # æ€§èƒ½ä¼˜åŒ–ç›¸å…³
        self.last_analysis_time = 0
        self.frame_cache = {}
        self.last_frame_hash = None
        
        # åˆ†æç»“æœç¼“å­˜
        self.analysis_cache = {}
        self.cache_ttl = 5.0  # ç¼“å­˜5ç§’
        
        logger.info(f"ğŸ”§ å±å¹•åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼ŒOCR: {'âœ…' if self.ocr_enabled else 'âŒ'}")
        
    def _check_ocr_available(self) -> bool:
        """æ£€æŸ¥OCRæ˜¯å¦å¯ç”¨"""
        try:
            pytesseract.get_tesseract_version()
            logger.info("âœ… Tesseract OCR å¯ç”¨")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ Tesseract OCR ä¸å¯ç”¨: {e}")
            return False
    
    async def analyze_screen_frame_async(self, frame: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        å¼‚æ­¥åˆ†æå±å¹•å¸§å†…å®¹
        åŒ…å«æ€§èƒ½ä¼˜åŒ–å’Œèµ„æºæ§åˆ¶
        """
        current_time = time.time()
        
        # å¸§ç‡æ§åˆ¶
        if current_time - self.last_analysis_time < (1.0 / self.max_analysis_fps):
            return None  # è·³è¿‡è¿™ä¸€å¸§
        
        # è®¡ç®—å¸§å“ˆå¸Œç”¨äºå»é‡
        frame_hash = self._compute_frame_hash(frame)
        if frame_hash == self.last_frame_hash:
            return None  # ä¸ä¸Šä¸€å¸§ç›¸åŒï¼Œè·³è¿‡
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.analysis_cache.get(frame_hash)
        if cached_result and (current_time - cached_result['timestamp']) < self.cache_ttl:
            logger.debug("ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ")
            return cached_result['data']
        
        # å¼‚æ­¥æ‰§è¡Œåˆ†æ
        try:
            result = await asyncio.get_event_loop().run_in_executor(
                None, self._analyze_frame_sync, frame
            )
            
            # æ›´æ–°ç¼“å­˜å’ŒçŠ¶æ€
            self.analysis_cache[frame_hash] = {
                'data': result,
                'timestamp': current_time
            }
            self.last_analysis_time = current_time
            self.last_frame_hash = frame_hash
            
            # æ¸…ç†è¿‡æœŸç¼“å­˜
            self._cleanup_cache(current_time)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥å±å¹•åˆ†æå¤±è´¥: {e}")
            return None
    
    def _analyze_frame_sync(self, frame: np.ndarray) -> Dict[str, Any]:
        """åŒæ­¥åˆ†æå¸§å†…å®¹ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šç¼©æ”¾å¸§å‡å°‘è®¡ç®—é‡
        if self.frame_resize_factor < 1.0:
            height, width = frame.shape[:2]
            new_height = int(height * self.frame_resize_factor)
            new_width = int(width * self.frame_resize_factor)
            frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)
        
        analysis_start = time.time()
        
        results = {
            'timestamp': time.time(),
            'frame_info': self._get_frame_info(frame),
            'text_content': None,
            'ui_elements': None,
            'scene_analysis': None,
            'performance_metrics': {}
        }
        
        # OCRæ–‡å­—è¯†åˆ«ï¼ˆæœ€è€—æ—¶çš„æ“ä½œï¼‰
        if self.ocr_enabled:
            ocr_start = time.time()
            results['text_content'] = self._extract_text_optimized(frame)
            results['performance_metrics']['ocr_time'] = time.time() - ocr_start
        
        # è½»é‡çº§UIå…ƒç´ æ£€æµ‹
        ui_start = time.time()
        results['ui_elements'] = self._detect_ui_elements_fast(frame)
        results['performance_metrics']['ui_detection_time'] = time.time() - ui_start
        
        # åœºæ™¯åˆ†æ
        scene_start = time.time()
        results['scene_analysis'] = self._analyze_scene_content(frame)
        results['performance_metrics']['scene_analysis_time'] = time.time() - scene_start
        
        # æ€»ä½“æ€§èƒ½æŒ‡æ ‡
        total_time = time.time() - analysis_start
        results['performance_metrics']['total_analysis_time'] = total_time
        
        logger.debug(f"ğŸ“Š å¸§åˆ†æå®Œæˆï¼Œè€—æ—¶: {total_time:.2f}s")
        
        return results
    
    def _compute_frame_hash(self, frame: np.ndarray) -> str:
        """è®¡ç®—å¸§çš„å“ˆå¸Œå€¼ç”¨äºå»é‡"""
        # å¤§å¹…ç¼©å°ç”¨äºå“ˆå¸Œè®¡ç®—
        small_frame = cv2.resize(frame, (32, 24))
        # è½¬æ¢ä¸ºç°åº¦
        gray_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)
        return hashlib.md5(gray_frame.tobytes()).hexdigest()[:16]
    
    def _get_frame_info(self, frame: np.ndarray) -> Dict[str, Any]:
        """è·å–å¸§åŸºæœ¬ä¿¡æ¯"""
        height, width = frame.shape[:2]
        
        # è®¡ç®—å›¾åƒç‰¹å¾
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        brightness = np.mean(gray)
        contrast = np.std(gray)
        
        return {
            'original_width': int(width / self.frame_resize_factor) if self.frame_resize_factor < 1.0 else width,
            'original_height': int(height / self.frame_resize_factor) if self.frame_resize_factor < 1.0 else height,
            'processed_width': width,
            'processed_height': height,
            'aspect_ratio': width / height,
            'brightness': float(brightness),
            'contrast': float(contrast),
            'resolution_category': self._categorize_resolution(width, height)
        }
    
    def _categorize_resolution(self, width: int, height: int) -> str:
        """åˆ†ç±»åˆ†è¾¨ç‡"""
        # è€ƒè™‘ç¼©æ”¾å› å­
        actual_width = int(width / self.frame_resize_factor) if self.frame_resize_factor < 1.0 else width
        
        if actual_width >= 3840:
            return "4K"
        elif actual_width >= 2560:
            return "2K"
        elif actual_width >= 1920:
            return "1080p"
        elif actual_width >= 1280:
            return "720p"
        else:
            return "ä½åˆ†è¾¨ç‡"
    
    def _extract_text_optimized(self, frame: np.ndarray) -> Optional[Dict[str, Any]]:
        """ä¼˜åŒ–çš„æ–‡å­—æå–"""
        if not self.ocr_enabled:
            return None
            
        try:
            # é¢„å¤„ç†æé«˜OCRå‡†ç¡®ç‡
            preprocessed = self._preprocess_for_ocr(frame)
            
            # ä½¿ç”¨æ›´å¿«çš„OCRé…ç½®
            custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.,!?@#$%^&*()_+-=[]{}|;:,.<>?/~` '
            
            # è½¬æ¢ä¸ºPILå›¾åƒ
            rgb_frame = cv2.cvtColor(preprocessed, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_frame)
            
            # OCRè¯†åˆ«
            text_data = pytesseract.image_to_data(
                pil_image, 
                output_type=pytesseract.Output.DICT,
                config=custom_config
            )
            
            # å¤„ç†ç»“æœ
            words = []
            confidences = []
            
            for i in range(len(text_data['text'])):
                text = text_data['text'][i].strip()
                conf = text_data['conf'][i]
                
                if text and conf > 40:  # æé«˜ç½®ä¿¡åº¦é˜ˆå€¼
                    words.append({
                        'text': text,
                        'confidence': conf,
                        'bbox': {
                            'x': text_data['left'][i],
                            'y': text_data['top'][i],
                            'width': text_data['width'][i],
                            'height': text_data['height'][i]
                        }
                    })
                    confidences.append(conf)
            
            full_text = ' '.join([word['text'] for word in words])
            avg_confidence = np.mean(confidences) if confidences else 0
            
            return {
                'full_text': full_text,
                'word_count': len(words),
                'words': words[:50],  # é™åˆ¶è¿”å›çš„è¯æ•°é‡
                'average_confidence': float(avg_confidence),
                'text_length': len(full_text)
            }
            
        except Exception as e:
            logger.error(f"âŒ OCRå¤„ç†å¤±è´¥: {e}")
            return None
    
    def _preprocess_for_ocr(self, frame: np.ndarray) -> np.ndarray:
        """OCRé¢„å¤„ç†"""
        # è½¬æ¢ä¸ºç°åº¦
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        # é™å™ª
        denoised = cv2.medianBlur(binary, 3)
        
        # è½¬æ¢å›BGRç”¨äºOCR
        return cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR)
    
    def _detect_ui_elements_fast(self, frame: np.ndarray) -> Dict[str, Any]:
        """å¿«é€ŸUIå…ƒç´ æ£€æµ‹"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨æ›´å¿«çš„è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 100, 200)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        rectangles = []
        buttons = []
        
        for contour in contours[:50]:  # é™åˆ¶å¤„ç†çš„è½®å»“æ•°é‡
            # è®¡ç®—è½®å»“é¢ç§¯ï¼Œè¿‡æ»¤å°å¯¹è±¡
            area = cv2.contourArea(contour)
            if area < 500:  # æœ€å°é¢ç§¯é˜ˆå€¼
                continue
                
            # è¿‘ä¼¼ä¸ºå¤šè¾¹å½¢
            epsilon = 0.02 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            if len(approx) == 4:  # çŸ©å½¢
                x, y, w, h = cv2.boundingRect(approx)
                
                element_data = {
                        'bbox': {'x': x, 'y': y, 'width': w, 'height': h},
                    'area': area,
                    'aspect_ratio': w / h if h > 0 else 0
                }
                
                # ç®€å•åˆ†ç±»
                if 0.8 <= w/h <= 5.0 and area < 5000:
                    buttons.append(element_data)
                else:
                    rectangles.append(element_data)
        
        return {
            'rectangles': rectangles[:20],  # é™åˆ¶æ•°é‡
            'buttons': buttons[:10],
            'total_ui_elements': len(rectangles) + len(buttons)
        }
    
    def _analyze_scene_content(self, frame: np.ndarray) -> Dict[str, Any]:
        """è½»é‡çº§åœºæ™¯å†…å®¹åˆ†æ"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—å›¾åƒç»Ÿè®¡ç‰¹å¾
        brightness = np.mean(gray)
        contrast = np.std(gray)
        
        # æ£€æµ‹å›¾åƒå¤æ‚åº¦
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # é¢œè‰²åˆ†æ
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        color_variance = np.var(hsv[:, :, 1])  # é¥±å’Œåº¦æ–¹å·®
        
        # ç®€å•åœºæ™¯åˆ†ç±»
        scene_type = "unknown"
        if brightness < 50:
            scene_type = "dark"
        elif brightness > 200:
            scene_type = "bright" 
        elif edge_density > 0.1:
            scene_type = "complex"
        elif color_variance > 1000:
            scene_type = "colorful"
        else:
            scene_type = "simple"
        
        return {
            'brightness': float(brightness),
            'contrast': float(contrast),
            'edge_density': float(edge_density),
            'color_variance': float(color_variance),
            'scene_type': scene_type,
            'complexity_score': float(edge_density * contrast / 100)
        }
    
    def _cleanup_cache(self, current_time: float):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        expired_keys = [
            key for key, value in self.analysis_cache.items()
            if current_time - value['timestamp'] > self.cache_ttl
        ]
        
        for key in expired_keys:
            del self.analysis_cache[key]
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.analysis_cache) > 50:
            # åˆ é™¤æœ€æ—§çš„æ¡ç›®
            oldest_key = min(
                self.analysis_cache.keys(),
                key=lambda k: self.analysis_cache[k]['timestamp']
            )
            del self.analysis_cache[oldest_key]

    def generate_ai_prompt(self, analysis_result: Dict[str, Any]) -> str:
        """
        åŸºäºåˆ†æç»“æœç”ŸæˆAIæç¤ºè¯
        """
        if not analysis_result:
            return ""
        
        prompt_parts = []
        
        # åŸºç¡€ä¿¡æ¯
        frame_info = analysis_result.get('frame_info', {})
        resolution = frame_info.get('resolution_category', 'æœªçŸ¥')
        brightness = frame_info.get('brightness', 0)
        
        prompt_parts.append(f"å½“å‰å±å¹•åˆ†è¾¨ç‡: {resolution}")
        
        # æ–‡å­—å†…å®¹
        text_content = analysis_result.get('text_content')
        if text_content and text_content.get('word_count', 0) > 0:
            text = text_content['full_text'][:300]  # é™åˆ¶é•¿åº¦
            word_count = text_content['word_count']
            confidence = text_content['average_confidence']
            
            prompt_parts.append(f"å±å¹•æ–‡å­—å†…å®¹(å…±{word_count}ä¸ªè¯ï¼Œç½®ä¿¡åº¦{confidence:.1f}%): {text}")
        
        # UIå…ƒç´ 
        ui_elements = analysis_result.get('ui_elements')
        if ui_elements:
            button_count = len(ui_elements.get('buttons', []))
            rect_count = len(ui_elements.get('rectangles', []))
            
            if button_count > 0:
                prompt_parts.append(f"æ£€æµ‹åˆ°{button_count}ä¸ªæŒ‰é’®å…ƒç´ ")
            if rect_count > 0:
                prompt_parts.append(f"æ£€æµ‹åˆ°{rect_count}ä¸ªçŸ©å½¢ç•Œé¢å…ƒç´ ")
        
        # åœºæ™¯åˆ†æ
        scene_analysis = analysis_result.get('scene_analysis')
        if scene_analysis:
            scene_type = scene_analysis.get('scene_type', 'unknown')
            complexity = scene_analysis.get('complexity_score', 0)
            
            prompt_parts.append(f"åœºæ™¯ç±»å‹: {scene_type}")
            if complexity > 5:
                prompt_parts.append("å±å¹•å†…å®¹è¾ƒä¸ºå¤æ‚")
        
        # æ€§èƒ½æŒ‡æ ‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        metrics = analysis_result.get('performance_metrics', {})
        total_time = metrics.get('total_analysis_time', 0)
        if total_time > 0:
            prompt_parts.append(f"åˆ†æè€—æ—¶: {total_time:.2f}ç§’")
        
        return "å±å¹•å…±äº«åˆ†æç»“æœ:\n" + "\n".join(prompt_parts)
```

### 4. LLMå±å¹•ç†è§£é›†æˆ

```python
# src/handlers/llm/screen_aware_llm_handler.py

import asyncio
from typing import Dict, Any, Optional, List
from loguru import logger
import time

from .openai_compatible.llm_handler_openai_compatible import HandlerLLM  
from .screen_content_analyzer import CloudOptimizedScreenAnalyzer
from ...chat_engine.data_models.runtime_data.chat_data import ChatData, ChatDataType

class ScreenAwareLLMHandler(HandlerLLM):
    """
    æ”¯æŒå±å¹•å…±äº«çš„AIå¯¹è¯å¤„ç†å™¨
    åŸºäºäº‘æœåŠ¡å™¨TURNåŸºç¡€è®¾æ–½ä¼˜åŒ–
    """
    
    def __init__(self):
        super().__init__()
        
        # åˆå§‹åŒ–å±å¹•åˆ†æå™¨
        self.screen_analyzer = CloudOptimizedScreenAnalyzer(
            ocr_enabled=True,
            max_analysis_fps=0.5,  # äº‘æœåŠ¡å™¨èµ„æºé™åˆ¶ï¼Œé™ä½åˆ°æ¯3ç§’åˆ†æä¸€æ¬¡
            frame_resize_factor=0.8  # è¿›ä¸€æ­¥å‡å°‘è®¡ç®—é‡
        )
        
        # å±å¹•ä¸Šä¸‹æ–‡ç®¡ç†
        self.current_screen_context = None
        self.screen_context_history = []
        self.max_history_length = 3  # å‡å°‘å†…å­˜ä½¿ç”¨
        
        # ä¸»åŠ¨å¯¹è¯æ§åˆ¶
        self.last_proactive_response_time = 0
        self.proactive_response_cooldown = 10.0  # 10ç§’å†·å´æ—¶é—´
        
        # æ€§èƒ½ç›‘æ§
        self.analysis_stats = {
            'total_frames_processed': 0,
            'successful_analyses': 0,
            'failed_analyses': 0,
            'avg_analysis_time': 0
        }
        
        logger.info("ğŸ¤– å±å¹•æ„ŸçŸ¥LLMå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def handle_screen_frame_async(self, context, inputs: ChatData):
        """
        å¼‚æ­¥å¤„ç†å±å¹•å¸§è¾“å…¥
        """
        if inputs.type != ChatDataType.CAMERA_VIDEO:
            return
            
        frame_data = inputs.data.get_main_data()
        if frame_data is None:
            return
            
        try:
            self.analysis_stats['total_frames_processed'] += 1
            
            # å¼‚æ­¥åˆ†æå±å¹•å†…å®¹
            analysis_result = await self.screen_analyzer.analyze_screen_frame_async(frame_data)
            
            if analysis_result is None:
                return  # è·³è¿‡çš„å¸§æˆ–ç¼“å­˜å‘½ä¸­
            
            self.analysis_stats['successful_analyses'] += 1
            
            # æ›´æ–°å½“å‰å±å¹•ä¸Šä¸‹æ–‡
            self.current_screen_context = analysis_result
            self._update_screen_context_history(analysis_result)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸»åŠ¨å“åº”
            await self._check_proactive_response(context, analysis_result)
            
        except Exception as e:
            self.analysis_stats['failed_analyses'] += 1
            logger.error(f"âŒ å±å¹•å¸§å¤„ç†å¤±è´¥: {e}")
    
    def _update_screen_context_history(self, analysis_result: Dict[str, Any]):
        """æ›´æ–°å±å¹•ä¸Šä¸‹æ–‡å†å²"""
        self.screen_context_history.append({
            'timestamp': analysis_result['timestamp'],
            'analysis': analysis_result
        })
        
        # ä¿æŒå†å²é•¿åº¦é™åˆ¶
        if len(self.screen_context_history) > self.max_history_length:
            self.screen_context_history.pop(0)
    
        logger.debug(f"ğŸ“š å±å¹•ä¸Šä¸‹æ–‡å†å²å·²æ›´æ–°ï¼Œå½“å‰é•¿åº¦: {len(self.screen_context_history)}")
    
    async def _check_proactive_response(self, context, analysis_result: Dict[str, Any]):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸»åŠ¨å“åº”"""
        current_time = time.time()
        
        # å†·å´æ—¶é—´æ£€æŸ¥
        if current_time - self.last_proactive_response_time < self.proactive_response_cooldown:
            return
        
        # æ£€æµ‹æ˜¾è‘—å˜åŒ–
        should_respond = self._detect_significant_changes(analysis_result)
        
        if should_respond:
            await self._generate_proactive_response(context, analysis_result)
            self.last_proactive_response_time = current_time
    
    def _detect_significant_changes(self, current_analysis: Dict[str, Any]) -> bool:
        """æ£€æµ‹å±å¹•å†…å®¹çš„æ˜¾è‘—å˜åŒ–"""
        if len(self.screen_context_history) < 2:
            return False
            
        previous_analysis = self.screen_context_history[-2]['analysis']
        
        # æ£€æŸ¥æ–‡å­—å†…å®¹å˜åŒ–
        current_text = current_analysis.get('text_content', {})
        previous_text = previous_analysis.get('text_content', {})
        
        current_words = current_text.get('word_count', 0)
        previous_words = previous_text.get('word_count', 0)
        
        # æ–‡å­—æ•°é‡æ˜¾è‘—å˜åŒ–
        if abs(current_words - previous_words) > 10:
            logger.info(f"ğŸ“ æ£€æµ‹åˆ°æ–‡å­—å†…å®¹æ˜¾è‘—å˜åŒ–: {previous_words} -> {current_words}")
                return True
                
        # æ£€æŸ¥åœºæ™¯ç±»å‹å˜åŒ–  
        current_scene = current_analysis.get('scene_analysis', {}).get('scene_type', '')
        previous_scene = previous_analysis.get('scene_analysis', {}).get('scene_type', '')
        
        if current_scene != previous_scene and current_scene not in ['unknown', '']:
            logger.info(f"ğŸ–¼ï¸ æ£€æµ‹åˆ°åœºæ™¯ç±»å‹å˜åŒ–: {previous_scene} -> {current_scene}")
            return True
        
        # æ£€æŸ¥UIå…ƒç´ å˜åŒ–
        current_ui_count = current_analysis.get('ui_elements', {}).get('total_ui_elements', 0)
        previous_ui_count = previous_analysis.get('ui_elements', {}).get('total_ui_elements', 0)
        
        if abs(current_ui_count - previous_ui_count) > 5:
            logger.info(f"ğŸ›ï¸ æ£€æµ‹åˆ°UIå…ƒç´ æ˜¾è‘—å˜åŒ–: {previous_ui_count} -> {current_ui_count}")
            return True
        
        return False
    
    async def _generate_proactive_response(self, context, analysis_result: Dict[str, Any]):
        """ç”Ÿæˆä¸»åŠ¨å“åº”"""
        try:
            # ç”ŸæˆåŸºäºå±å¹•å†…å®¹çš„ä¸»åŠ¨æç¤º
            suggestions = self._generate_smart_suggestions(analysis_result)
            
            if suggestions:
                suggestion = suggestions[0]  # é€‰æ‹©ç¬¬ä¸€ä¸ªå»ºè®®
                logger.info(f"ğŸ¤– ç”Ÿæˆä¸»åŠ¨å»ºè®®: {suggestion}")
                
                # è¿™é‡Œå¯ä»¥è§¦å‘TTSè¾“å‡ºæˆ–è€…é€šè¿‡å…¶ä»–æ–¹å¼å‘é€ç»™ç”¨æˆ·
                # å…·ä½“å®ç°å–å†³äºç°æœ‰çš„è¾“å‡ºæœºåˆ¶
                
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆä¸»åŠ¨å“åº”å¤±è´¥: {e}")
    
    def _generate_smart_suggestions(self, analysis_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ™ºèƒ½å»ºè®®"""
        suggestions = []
        
        # åŸºäºæ–‡å­—å†…å®¹çš„å»ºè®®
        text_content = analysis_result.get('text_content')
        if text_content:
            word_count = text_content.get('word_count', 0)
            text = text_content.get('full_text', '')
            
            if word_count > 50:
                suggestions.append("æˆ‘çœ‹åˆ°å±å¹•ä¸Šæœ‰å¤§é‡æ–‡å­—ï¼Œéœ€è¦æˆ‘å¸®æ‚¨æ€»ç»“ä¸»è¦å†…å®¹å—ï¼Ÿ")
            elif 'é”™è¯¯' in text or 'error' in text.lower() or 'å¤±è´¥' in text:
                suggestions.append("æˆ‘æ³¨æ„åˆ°å±å¹•ä¸Šä¼¼ä¹æœ‰é”™è¯¯ä¿¡æ¯ï¼Œéœ€è¦æˆ‘å¸®æ‚¨åˆ†æé—®é¢˜å—ï¼Ÿ")
            elif 'ç™»å½•' in text or 'login' in text.lower():
                suggestions.append("çœ‹èµ·æ¥æ‚¨åœ¨ç™»å½•ç•Œé¢ï¼Œæœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ")
        
        # åŸºäºUIå…ƒç´ çš„å»ºè®®
        ui_elements = analysis_result.get('ui_elements')
        if ui_elements:
            button_count = len(ui_elements.get('buttons', []))
            if button_count > 10:
                suggestions.append("å±å¹•ä¸Šæœ‰å¾ˆå¤šæŒ‰é’®ï¼Œéœ€è¦æˆ‘æŒ‡å¯¼æ‚¨å¦‚ä½•æ“ä½œå—ï¼Ÿ")
        
        # åŸºäºåœºæ™¯ç±»å‹çš„å»ºè®®
        scene_analysis = analysis_result.get('scene_analysis')
        if scene_analysis:
            scene_type = scene_analysis.get('scene_type', '')
            complexity = scene_analysis.get('complexity_score', 0)
            
            if scene_type == 'complex' and complexity > 10:
                suggestions.append("å½“å‰ç•Œé¢æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ç†è§£å±å¹•ä¸Šçš„å†…å®¹")
            elif scene_type == 'dark':
                suggestions.append("å±å¹•æ¯”è¾ƒæš—ï¼Œæ˜¯å¦éœ€è¦è°ƒæ•´æ˜¾ç¤ºè®¾ç½®ï¼Ÿ")
        
        return suggestions
    
    def _enhance_prompt_with_screen_context(self, original_prompt: str) -> str:
        """ä½¿ç”¨å±å¹•ä¸Šä¸‹æ–‡å¢å¼ºæç¤ºè¯"""
        if not self.current_screen_context:
            return original_prompt
        
        # ç”Ÿæˆå±å¹•ä¸Šä¸‹æ–‡æè¿°
        screen_context = self.screen_analyzer.generate_ai_prompt(self.current_screen_context)
        
        if not screen_context.strip():
            return original_prompt
        
        enhanced_prompt = f"""
ç”¨æˆ·æ­£åœ¨è¿›è¡Œå±å¹•å…±äº«ï¼Œä»¥ä¸‹æ˜¯å½“å‰å±å¹•å†…å®¹åˆ†æï¼š

{screen_context}

åŸºäºä¸Šè¿°å±å¹•ä¿¡æ¯ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š{original_prompt}

å¦‚æœé—®é¢˜ä¸å±å¹•å†…å®¹ç›¸å…³ï¼Œè¯·ç»“åˆå±å¹•ä¿¡æ¯ç»™å‡ºå…·ä½“çš„å»ºè®®ã€‚å¦‚æœå±å¹•å†…å®¹ä¸é—®é¢˜æ— å…³ï¼Œè¯·æ­£å¸¸å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
"""
        return enhanced_prompt
    
    def handle(self, context, inputs: ChatData, output_definitions: Dict[ChatDataType, Any]):
        """
        é‡å†™handleæ–¹æ³•ä»¥æ”¯æŒå±å¹•ä¸Šä¸‹æ–‡
        """
        
        # å¤„ç†å±å¹•è§†é¢‘è¾“å…¥ï¼ˆå¼‚æ­¥ï¼‰
        if inputs.type == ChatDataType.CAMERA_VIDEO:
            # å¯åŠ¨å¼‚æ­¥å¤„ç†ï¼Œä¸é˜»å¡ä¸»æµç¨‹
            asyncio.create_task(self.handle_screen_frame_async(context, inputs))
            return  # å±å¹•å¸§å¤„ç†ä¸éœ€è¦ç«‹å³å“åº”
        
        # å¤„ç†æ–‡æœ¬è¾“å…¥
        if inputs.type == ChatDataType.HUMAN_TEXT:
            original_text = inputs.data.get_main_data()
            
            # ä½¿ç”¨å±å¹•ä¸Šä¸‹æ–‡å¢å¼ºæç¤ºè¯
            enhanced_text = self._enhance_prompt_with_screen_context(original_text)
            
            # åˆ›å»ºå¢å¼ºçš„è¾“å…¥æ•°æ®
            enhanced_inputs = ChatData(
                source=inputs.source,
                type=inputs.type,
                timestamp=inputs.timestamp,
                data=inputs.data.__class__(enhanced_text)
            )
            
            # è®°å½•å¤„ç†ç»Ÿè®¡
            logger.debug(f"ğŸ“Š å±å¹•åˆ†æç»Ÿè®¡: {self.analysis_stats}")
            
            # è°ƒç”¨çˆ¶ç±»å¤„ç†æ–¹æ³•
            return super().handle(context, enhanced_inputs, output_definitions)
        
        # å…¶ä»–ç±»å‹çš„è¾“å…¥ç›´æ¥è°ƒç”¨çˆ¶ç±»æ–¹æ³•
        return super().handle(context, inputs, output_definitions)
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        total_processed = self.analysis_stats['total_frames_processed']
        successful = self.analysis_stats['successful_analyses']
        
        success_rate = (successful / total_processed * 100) if total_processed > 0 else 0
        
        return {
            **self.analysis_stats,
            'success_rate': success_rate,
            'context_history_length': len(self.screen_context_history),
            'has_current_context': self.current_screen_context is not None
        }
```

---

## ğŸš€ å®æ–½è®¡åˆ’å’Œå¼€å‘æ­¥éª¤

### é˜¶æ®µ1ï¼šåŸºç¡€å±å¹•æ•è· (1å‘¨)

**ç›®æ ‡**ï¼šå®ç°åŸºç¡€çš„å±å¹•å…±äº«åŠŸèƒ½

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] å®ç° `getTurnOptimizedDisplayStream` å‡½æ•°
- [ ] åˆ›å»º `ScreenShareStore` çŠ¶æ€ç®¡ç†
- [ ] å¼€å‘ `ScreenShareControl` Vueç»„ä»¶
- [ ] é›†æˆTURNæœåŠ¡å™¨é…ç½® (8.138.87.249:3478)
- [ ] åŸºç¡€çš„è®¾å¤‡å…¼å®¹æ€§æ£€æµ‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… èƒ½å¤Ÿå¯åŠ¨å±å¹•å…±äº«å¹¶åœ¨WebRTC-Internalsä¸­çœ‹åˆ°TURNä¸­ç»§
- âœ… æ”¯æŒæ¡Œé¢/çª—å£/æ ‡ç­¾é¡µä¸‰ç§æ•è·æ¨¡å¼
- âœ… çŠ¶æ€æŒ‡ç¤ºå™¨æ˜¾ç¤ºæ­£ç¡®çš„è¿æ¥çŠ¶æ€

**å¼€å‘å‘½ä»¤**ï¼š
```bash
# ç¬¬ä¸€å‘¨å¼€å‘ç¯å¢ƒå‡†å¤‡
cd src/handlers/client/rtc_client/frontend

# å®‰è£…å¯èƒ½éœ€è¦çš„é¢å¤–ä¾èµ–
npm install @vueuse/core

# åˆ›å»ºå±å¹•å…±äº«ç›¸å…³æ–‡ä»¶
mkdir -p src/utils src/store src/components
touch src/utils/screenShareUtils.ts
touch src/store/screenShareStore.ts  
touch src/components/ScreenShareControl.vue

# å¼€å§‹å¼€å‘
npm run dev
```

### é˜¶æ®µ2ï¼šåç«¯åˆ†æé›†æˆ (1-2å‘¨)

**ç›®æ ‡**ï¼šå®ç°å±å¹•å†…å®¹æ™ºèƒ½åˆ†æ

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] å®‰è£…å’Œé…ç½®Tesseract OCR
- [ ] å®ç° `CloudOptimizedScreenAnalyzer`
- [ ] åˆ›å»ºå¼‚æ­¥å¸§å¤„ç†ç®¡é“
- [ ] é›†æˆåˆ°ç°æœ‰LLMå¤„ç†æµç¨‹

**ç¯å¢ƒå‡†å¤‡**ï¼š
```bash
# å®‰è£…OCRä¾èµ– (åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒ)
# Windows (éœ€è¦å®‰è£…Tesseract)
# https://github.com/UB-Mannheim/tesseract/wiki

# Pythonä¾èµ–
pip install pytesseract opencv-python pillow

# åˆ›å»ºåç«¯åˆ†ææ¨¡å—
touch src/handlers/llm/screen_content_analyzer.py
touch src/handlers/llm/screen_aware_llm_handler.py
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… OCRèƒ½å¤Ÿè¯†åˆ«å±å¹•ä¸­çš„æ–‡å­—å†…å®¹
- âœ… UIå…ƒç´ æ£€æµ‹åŸºæœ¬å¯ç”¨
- âœ… AIå¯¹è¯èƒ½å¤Ÿç†è§£å±å¹•ä¸Šä¸‹æ–‡
- âœ… æ€§èƒ½æ»¡è¶³äº‘æœåŠ¡å™¨é™åˆ¶ (æ¯å¸§å¤„ç†<1ç§’)

### é˜¶æ®µ3ï¼šæ€§èƒ½ä¼˜åŒ–å’Œå®Œå–„ (1å‘¨)

**ç›®æ ‡**ï¼šä¼˜åŒ–æ€§èƒ½å¹¶å®Œå–„ç”¨æˆ·ä½“éªŒ

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] å®ç°è‡ªé€‚åº”è´¨é‡è°ƒæ•´
- [ ] æ·»åŠ è¿æ¥è´¨é‡ç›‘æ§
- [ ] ä¼˜åŒ–ç¼“å­˜å’Œå†…å­˜ä½¿ç”¨
- [ ] ç§»åŠ¨ç«¯é€‚é…

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… åœ¨1æ ¸2Gäº‘æœåŠ¡å™¨ä¸Šç¨³å®šè¿è¡Œ
- âœ… ç§»åŠ¨ç«¯è®¾å¤‡èƒ½å¤Ÿæ­£å¸¸ä½¿ç”¨å±å¹•å…±äº«
- âœ… ç½‘ç»œè´¨é‡å·®æ—¶èƒ½å¤Ÿè‡ªåŠ¨é™ä½è´¨é‡
- âœ… å†…å­˜ä½¿ç”¨æ§åˆ¶åœ¨åˆç†èŒƒå›´

### é˜¶æ®µ4ï¼šæµ‹è¯•å’Œéƒ¨ç½² (0.5å‘¨)

**ç›®æ ‡**ï¼šå…¨é¢æµ‹è¯•å¹¶éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

**æµ‹è¯•æ¸…å•**ï¼š
- [ ] **TURNè¿æ¥æµ‹è¯•**ï¼šéªŒè¯ä¸ç°æœ‰TURNæœåŠ¡å™¨çš„å…¼å®¹æ€§
- [ ] **è·¨æµè§ˆå™¨æµ‹è¯•**ï¼šChrome, Firefox, Safari, Edge
- [ ] **ç§»åŠ¨ç«¯æµ‹è¯•**ï¼šAndroid Chrome, iOS Safari
- [ ] **ç½‘ç»œç¯å¢ƒæµ‹è¯•**ï¼šWiFi, ç§»åŠ¨æ•°æ®, ä¸åŒå¸¦å®½
- [ ] **æ€§èƒ½å‹åŠ›æµ‹è¯•**ï¼šé•¿æ—¶é—´å±å¹•å…±äº«çš„ç¨³å®šæ€§

**éƒ¨ç½²éªŒè¯**ï¼š
```bash
# éªŒè¯TURNæœåŠ¡å™¨è¿æ¥æ€§
Test-NetConnection -ComputerName 8.138.87.249 -Port 3478

# è¿è¡Œç°æœ‰éªŒè¯è„šæœ¬
sudo bash verify_turn_setup.sh

# å¯åŠ¨é¡¹ç›®æµ‹è¯•å±å¹•å…±äº«
04è¿è¡Œç¨‹åº-lam-VL.bat
```

---

## ğŸ¯ é¢„æœŸæ•ˆæœå’ŒæˆåŠŸæ ‡å¿—

### åŠŸèƒ½ç›®æ ‡è¾¾æˆ

1. **è·¨ç½‘ç»œå±å¹•å…±äº«** âœ…
   - åŸºäºç°æœ‰TURNåŸºç¡€è®¾æ–½å®ç°ç¨³å®šçš„å±å¹•å…±äº«
   - æ”¯æŒå†…ç½‘ç©¿é€ç¯å¢ƒä¸‹çš„å¯é è¿æ¥

2. **æ™ºèƒ½å†…å®¹ç†è§£** âœ…  
   - AIèƒ½å¤Ÿç†è§£å±å¹•å†…å®¹å¹¶æä¾›é’ˆå¯¹æ€§å»ºè®®
   - OCRæ–‡å­—è¯†åˆ«å‡†ç¡®ç‡>80%

3. **æ€§èƒ½ä¼˜åŒ–** âœ…
   - é€‚é…1æ ¸2Gäº‘æœåŠ¡å™¨ç¯å¢ƒ
   - ç§»åŠ¨ç«¯æµç•…ä½“éªŒ

### æŠ€æœ¯æŒ‡æ ‡éªŒæ”¶

**WebRTCè¿æ¥æŒ‡æ ‡**ï¼š
```
ICE connection state: connected âœ…
TURNå€™é€‰è€…: candidateType: relay âœ…  
åª’ä½“æµè´¨é‡: >720p@8fps (ç§»åŠ¨) / >1080p@10fps (æ¡Œé¢) âœ…
è¿æ¥å»¶è¿Ÿ: <500ms âœ…
```

**AIåˆ†ææŒ‡æ ‡**ï¼š
```
OCRè¯†åˆ«å‡†ç¡®ç‡: >80% âœ…
å¸§åˆ†æå»¶è¿Ÿ: <2ç§’ âœ…
å†…å­˜ä½¿ç”¨: <200MB âœ…
æˆåŠŸåˆ†æç‡: >90% âœ…
```

**ç”¨æˆ·ä½“éªŒæŒ‡æ ‡**ï¼š
```
å¯åŠ¨å±å¹•å…±äº«: <5ç§’ âœ…
åˆ‡æ¢æ‘„åƒå¤´/å±å¹•: <3ç§’ âœ…
AIä¸Šä¸‹æ–‡å“åº”: <10ç§’ âœ…
ç§»åŠ¨ç«¯å…¼å®¹æ€§: >80% âœ…
```

---

---

## ğŸ¯ **å½“å‰å®ç°æ–¹æ¡ˆ (å·²å®Œæˆ)**

### ğŸ“‹ **å®ç°æ¦‚è¿°**

æˆ‘ä»¬å·²ç»æˆåŠŸå®ç°äº†åŸºäºWebRTCçš„å±å¹•å…±äº«åŠŸèƒ½ï¼ŒåŒ…å«å®Œæ•´çš„å‰ç«¯UIã€çŠ¶æ€ç®¡ç†ã€è½¨é“æ›¿æ¢æœºåˆ¶ï¼Œä»¥åŠä¸æ‘„åƒå¤´åŠŸèƒ½çš„æ™ºèƒ½é›†æˆã€‚

### ğŸ—ï¸ **æ ¸å¿ƒæ¶æ„**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     å‰ç«¯æ¶æ„ (Vue3 + Pinia)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ActionGroup.vue           â”‚  screenShareStore.ts           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ¥ æ‘„åƒå¤´æŒ‰é’®       â”‚   â”‚  â”‚ ğŸ“± å±å¹•å…±äº«çŠ¶æ€ç®¡ç†        â”‚ â”‚
â”‚  â”‚ (æ™ºèƒ½éšè—/æ˜¾ç¤º)     â”‚   â”‚  â”‚ â€¢ isScreenSharing          â”‚ â”‚
â”‚  â”‚                     â”‚   â”‚  â”‚ â€¢ screenShareSupported     â”‚ â”‚
â”‚  â”‚ ğŸ“º å±å¹•å…±äº«æŒ‰é’®     â”‚   â”‚  â”‚ â€¢ cameraStateBeforeShare   â”‚ â”‚
â”‚  â”‚ (åŠ¨æ€å›¾æ ‡åˆ‡æ¢)      â”‚   â”‚  â”‚ â€¢ è‡ªåŠ¨è½¨é“æ›¿æ¢é€»è¾‘        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ replaceTrack()
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WebRTC PeerConnection                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“¹ Video Sender                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Track: æ‘„åƒå¤´æµ â”€â”€â–¶ replaceTrack() â”€â”€â–¶ å±å¹•å…±äº«æµ      â”‚ â”‚
â”‚  â”‚              â—€â”€â”€ replaceTrack() â—€â”€â”€                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  ğŸ¤ Audio Sender (éº¦å…‹é£ï¼Œä¸å˜)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ åª’ä½“æµ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      åç«¯å¤„ç†                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AIæ¥æ”¶: æ‘„åƒå¤´ç”»é¢ â”€â”€â–¶ å±å¹•å…±äº«å†…å®¹ â”€â”€â–¶ æ‘„åƒå¤´ç”»é¢        â”‚
â”‚  å®æ—¶åˆ†æ: "æˆ‘çœ‹åˆ°ä½ " â”€â”€â–¶ "ä½ çš„å±å¹•æ˜¾ç¤º..." â”€â”€â–¶ "åˆçœ‹åˆ°ä½ "   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ **æ ¸å¿ƒå®ç°é€»è¾‘**

#### 1. **æ™ºèƒ½UIç®¡ç†**

**æ–‡ä»¶**: `OpenAvatarChat-WebUI/src/components/ActionGroup.vue`

```vue
<!-- æ ¸å¿ƒé€»è¾‘ï¼šå±å¹•å…±äº«æ—¶è‡ªåŠ¨éšè—æ‘„åƒå¤´æŒ‰é’® -->
<div v-if="hasCamera && !isScreenSharing">
  <!-- æ‘„åƒå¤´æ§åˆ¶æŒ‰é’®å’Œé¢æ¿ -->
</div>

<div v-if="screenShareSupported" class="action" @click="handleScreenShare">
  <Iconfont :icon="isScreenSharing ? ScreenShareStop : ScreenShare" />
</div>
```

**å…³é”®å®ç°**ï¼š
- âœ… **æ¡ä»¶æ¸²æŸ“**: `v-if="hasCamera && !isScreenSharing"` ç¡®ä¿å±å¹•å…±äº«æ—¶æ‘„åƒå¤´æŒ‰é’®æ¶ˆå¤±
- âœ… **å“åº”å¼çŠ¶æ€**: ä½¿ç”¨`computed`å“åº”å¼è®¿é—®`screenShareSupported`å’Œ`isScreenSharing`
- âœ… **å®æ—¶ç›‘å¬**: `watchEffect()`å®æ—¶ç›‘å¬çŠ¶æ€å˜åŒ–å¹¶è¾“å‡ºè°ƒè¯•æ—¥å¿—

#### 2. **çŠ¶æ€ç®¡ç†ä¸è‡ªåŠ¨åˆ‡æ¢**

**æ–‡ä»¶**: `OpenAvatarChat-WebUI/src/store/screenShareStore.ts`

```typescript
// ğŸ“· æ‘„åƒå¤´çŠ¶æ€è®°å¿†ï¼ˆå…³é”®åˆ›æ–°ï¼‰
let cameraStateBeforeScreenShare: boolean = false;

// ğŸš€ å±å¹•å…±äº«å¼€å§‹é€»è¾‘
async function startScreenShare() {
  // 1. è®°ä½å½“å‰æ‘„åƒå¤´æ˜¾ç¤ºçŠ¶æ€
  const videoChatStore = useVideoChatStore();
  cameraStateBeforeScreenShare = !videoChatStore.cameraOff;
  
  // 2. è‡ªåŠ¨å…³é—­æ‘„åƒå¤´æ˜¾ç¤ºä»¥é¿å…å¹²æ‰°
  if (cameraStateBeforeScreenShare) {
    console.log('ğŸ“· è‡ªåŠ¨å…³é—­æ‘„åƒå¤´æ˜¾ç¤ºä»¥é¿å…å¹²æ‰°');
    videoChatStore.handleCameraOff();
  }
  
  // 3. è·å–å±å¹•å…±äº«æµ
  const displayStream = await getOptimizedDisplayStream({...});
  
  // 4. ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ›¿æ¢WebRTCè§†é¢‘è½¨é“
  await replaceVideoTrack(displayStream);
  console.log('ğŸ‰ æˆåŠŸï¼AIç°åœ¨èƒ½çœ‹åˆ°å±å¹•å†…å®¹ï¼');
}

// ğŸ›‘ å±å¹•å…±äº«åœæ­¢é€»è¾‘  
async function stopScreenShare() {
  // 1. ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ¢å¤æ‘„åƒå¤´è½¨é“
  const videoChatStore = useVideoChatStore();
  if (videoChatStore.localStream) {
    await replaceVideoTrack(videoChatStore.localStream);
    console.log('ğŸ‰ å·²æ¢å¤æ‘„åƒå¤´è½¨é“ï¼ŒAIé‡æ–°çœ‹åˆ°æ‘„åƒå¤´ï¼');
  }
  
  // 2. ğŸ“· è‡ªåŠ¨æ¢å¤æ‘„åƒå¤´æ˜¾ç¤ºçŠ¶æ€
  if (cameraStateBeforeScreenShare && videoChatStore.cameraOff) {
    console.log('ğŸ“· è‡ªåŠ¨æ¢å¤æ‘„åƒå¤´æ˜¾ç¤ºçŠ¶æ€');
    videoChatStore.handleCameraOff(); // é‡æ–°å¼€å¯æ˜¾ç¤º
  }
}
```

#### 3. **WebRTCè½¨é“æ›¿æ¢æœºåˆ¶**

**å…³é”®å‡½æ•°**: `replaceVideoTrack()`

```typescript
async function replaceVideoTrack(newStream: MediaStream) {
  if (!peerConnection) return;
  
  // æ‰¾åˆ°è§†é¢‘å‘é€å™¨
  const videoSender = peerConnection.getSenders().find(
    sender => sender.track && sender.track.kind === 'video'
  );
  
  if (videoSender && newStream.getVideoTracks().length > 0) {
    const newVideoTrack = newStream.getVideoTracks()[0];
    
    console.log('ğŸ” è½¨é“æ›¿æ¢è¯¦æƒ…:', {
      oldTrack: videoSender.track?.label,
      newTrack: newVideoTrack.label,
      newTrackEnabled: newVideoTrack.enabled,
      newTrackReadyState: newVideoTrack.readyState
    });
    
    // ğŸ”¥ æ ¸å¿ƒAPIè°ƒç”¨
    await videoSender.replaceTrack(newVideoTrack);
    console.log('ğŸ“¹ è§†é¢‘è½¨é“å·²æˆåŠŸæ›¿æ¢ï¼AIç°åœ¨èƒ½çœ‹åˆ°æ–°çš„è§†é¢‘æµ');
  }
}
```

### ğŸ”§ **å·²è§£å†³çš„å…³é”®é—®é¢˜**

#### é—®é¢˜1: AIçœ‹ä¸åˆ°å±å¹•å†…å®¹ âŒâ†’âœ…

**ç—‡çŠ¶**: ç”¨æˆ·æŠ¥å‘Š"å¤§æ¨¡å‹å›å¤ä»–çœ‹ä¸åˆ°ä»»ä½•å›¾ç‰‡"æˆ–"æ¥æ”¶åˆ°çš„å›¾ç‰‡æ˜¯çº¯é»‘çš„"

**æ ¹æœ¬åŸå› **: å±å¹•å…±äº«è§†é¢‘æµæ²¡æœ‰æ›¿æ¢WebRTCè¿æ¥ä¸­çš„æ‘„åƒå¤´è½¨é“

**è§£å†³æ–¹æ¡ˆ**: å®ç°`replaceVideoTrack()`æœºåˆ¶
```typescript
// ä¿®å¤å‰ï¼šåªè·å–å±å¹•æµï¼Œä½†AIä»æ¥æ”¶æ‘„åƒå¤´æµ
const displayStream = await getDisplayMedia();
// âŒ æ²¡æœ‰æ›¿æ¢è½¨é“ï¼ŒAIçœ‹ä¸åˆ°å±å¹•å†…å®¹

// ä¿®å¤åï¼šè·å–å±å¹•æµå¹¶æ›¿æ¢WebRTCè½¨é“  
const displayStream = await getDisplayMedia();
await replaceVideoTrack(displayStream); // âœ… AIç°åœ¨èƒ½çœ‹åˆ°å±å¹•
```

#### é—®é¢˜1.5: æ‘„åƒå¤´ä¸€å¼€å§‹å…³é—­æ—¶æ— æ³•å±å¹•å…±äº« âŒâ†’âœ…

**ç—‡çŠ¶**: å¦‚æœç”¨æˆ·ä¸€å¼€å§‹å°±å…³é—­äº†æ‘„åƒå¤´ï¼Œå¯åŠ¨å±å¹•å…±äº«æ—¶AIä»ç„¶çœ‹ä¸åˆ°å†…å®¹

**æ ¹æœ¬åŸå› **: æ‘„åƒå¤´è½¨é“è¢«ç¦ç”¨æ—¶ï¼Œæ²¡æœ‰æ´»è·ƒçš„WebRTCè§†é¢‘è½¨é“å¯ä»¥è¢«æ›¿æ¢

**è§£å†³æ–¹æ¡ˆ**: æ™ºèƒ½æ‘„åƒå¤´çŠ¶æ€ç®¡ç†
```typescript
// ğŸ¯ æ–°å¢ä¿®å¤ï¼šç¡®ä¿æ‘„åƒå¤´è½¨é“å¯ç”¨ä»¥æ”¯æŒWebRTCè½¨é“æ›¿æ¢
if (videoChatStore.cameraOff) {
  console.log('ğŸ”§ ç”¨æˆ·æ‘„åƒå¤´åŸæœ¬æ˜¯å…³é—­çš„ï¼Œç°åœ¨è‡ªåŠ¨å¯ç”¨è½¨é“ä»¥æ”¯æŒå±å¹•å…±äº«');
  videoChatStore.handleCameraOff(); // å¯ç”¨è½¨é“
}

// éšè—æ‘„åƒå¤´æ˜¾ç¤ºï¼ˆä½†ä¿æŒè½¨é“å¯ç”¨çŠ¶æ€ï¼‰
videoChatStore.handleCameraOff(); // å…³é—­æ˜¾ç¤º

// è·å–å±å¹•æµå¹¶æ›¿æ¢
await replaceVideoTrack(displayStream); // âœ… ç°åœ¨å¯ä»¥æˆåŠŸæ›¿æ¢äº†
```

#### é—®é¢˜2: å‰ç«¯è·¯ç”±404é”™è¯¯ âŒâ†’âœ…

**ç—‡çŠ¶**: `GET https://liao.uunat.com:8282/webui/ 404 (Not Found)`

**æ ¹æœ¬åŸå› **: FastAPIé™æ€æ–‡ä»¶é…ç½®å†²çª
```python
# ä¿®å¤å‰ï¼šè·¯ç”±å†²çª
@app.get("/webui/")  # ä¸ä¸‹é¢çš„mountå†²çª
app.mount("/webui", StaticFiles(directory=webui_dir), name="webui")

# ä¿®å¤åï¼šä½¿ç”¨html=Trueé¿å…å†²çª
app.mount("/webui", StaticFiles(directory=webui_dir, html=True), name="webui")
# åˆ é™¤äº†æ˜¾å¼çš„@app.get("/webui/")è·¯ç”±
```

#### é—®é¢˜3: æŒ‰é’®æ˜¾ç¤ºçŠ¶æ€é—®é¢˜ âŒâ†’âœ…

**ç—‡çŠ¶**: æ‘„åƒå¤´æŒ‰é’®åœ¨æ¡Œé¢æ¶ˆå¤±ï¼Œå±å¹•å…±äº«æŒ‰é’®åœ¨ç§»åŠ¨ç«¯æ¶ˆå¤±

**æ ¹æœ¬åŸå› **: çŠ¶æ€ç›‘å¬æ—¶åºé—®é¢˜å’Œå“åº”å¼è®¿é—®é”™è¯¯
```typescript
// ä¿®å¤å‰ï¼šçŠ¶æ€æ£€æµ‹åœ¨æƒé™æˆäºˆå‰æ‰§è¡Œ
console.log('æŒ‰é’®æ˜¾ç¤ºçŠ¶æ€:', {...}); // åªæ‰§è¡Œä¸€æ¬¡ï¼Œå¤ªæ—©äº†

// ä¿®å¤åï¼šå®æ—¶ç›‘å¬çŠ¶æ€å˜åŒ–
watchEffect(() => {
  console.log('å®æ—¶çŠ¶æ€:', {...}); // å“åº”çŠ¶æ€å˜åŒ–
});
```

#### é—®é¢˜4: æ‘„åƒå¤´ä¸å±å¹•å…±äº«å†²çª âŒâ†’âœ…

**ç—‡çŠ¶**: å±å¹•å…±äº«æ—¶æ‘„åƒå¤´ç”»é¢ä»ç„¶æ˜¾ç¤ºï¼Œç”¨æˆ·å›°æƒ‘

**è§£å†³æ–¹æ¡ˆ**: æ™ºèƒ½çŠ¶æ€è®°å¿†å’Œè‡ªåŠ¨åˆ‡æ¢
```typescript
// å±å¹•å…±äº«å¼€å§‹ï¼šè®°å¿†çŠ¶æ€ + è‡ªåŠ¨å…³é—­æ‘„åƒå¤´æ˜¾ç¤º
cameraStateBeforeScreenShare = !videoChatStore.cameraOff;
if (cameraStateBeforeScreenShare) {
  videoChatStore.handleCameraOff(); // å…³é—­æ˜¾ç¤º
}

// å±å¹•å…±äº«ç»“æŸï¼šæ¢å¤åŸå§‹çŠ¶æ€  
if (cameraStateBeforeScreenShare && videoChatStore.cameraOff) {
  videoChatStore.handleCameraOff(); // æ¢å¤æ˜¾ç¤º
}
```

### ğŸ“Š **ç”¨æˆ·ä½“éªŒæµç¨‹**

#### ç†æƒ³çš„ç”¨æˆ·æ“ä½œæµç¨‹

```
1. ç”¨æˆ·å¼€å¯æ‘„åƒå¤´ 
   â””â”€ ç•Œé¢: [ğŸ¥æ‘„åƒå¤´] [ğŸ¤éº¦å…‹é£] [ğŸ”ŠéŸ³é‡] [ğŸ“ºå±å¹•å…±äº«] [ğŸ“å­—å¹•]
   â””â”€ AI: "æˆ‘å¯ä»¥çœ‹åˆ°ä½ "

2. ç”¨æˆ·ç‚¹å‡»å±å¹•å…±äº«
   â””â”€ ç•Œé¢: [ğŸ¤éº¦å…‹é£] [ğŸ”ŠéŸ³é‡] [â¹ï¸åœæ­¢å…±äº«] [ğŸ“å­—å¹•]  (æ‘„åƒå¤´æŒ‰é’®è‡ªåŠ¨æ¶ˆå¤±)
   â””â”€ AI: "ç°åœ¨æˆ‘çœ‹åˆ°ä½ çš„å±å¹•æ˜¾ç¤ºç€..."

3. ç”¨æˆ·åœæ­¢å±å¹•å…±äº«  
   â””â”€ ç•Œé¢: [ğŸ¥æ‘„åƒå¤´] [ğŸ¤éº¦å…‹é£] [ğŸ”ŠéŸ³é‡] [ğŸ“ºå±å¹•å…±äº«] [ğŸ“å­—å¹•]  (æŒ‰é’®è‡ªåŠ¨æ¢å¤)
   â””â”€ AI: "ç°åœ¨æˆ‘åˆèƒ½çœ‹åˆ°ä½ äº†"
```

#### å„ç§åœºæ™¯çš„å¤„ç†

**åœºæ™¯A: æ‘„åƒå¤´æ˜¾ç¤ºå¼€å¯ â†’ å±å¹•å…±äº« â†’ åœæ­¢å…±äº«**
```
âœ… æ‘„åƒå¤´è½¨é“ï¼šå¯ç”¨ â†’ ä¿æŒå¯ç”¨(æ›¿æ¢ä¸ºå±å¹•) â†’ æ¢å¤æ‘„åƒå¤´
âœ… æ‘„åƒå¤´æ˜¾ç¤ºï¼šå¼€å¯ â†’ è‡ªåŠ¨å…³é—­æ˜¾ç¤º â†’ è‡ªåŠ¨æ¢å¤æ˜¾ç¤º
âœ… AIè§†è§’ï¼šçœ‹åˆ°äººè„¸ â†’ çœ‹åˆ°å±å¹•å†…å®¹ â†’ é‡æ–°çœ‹åˆ°äººè„¸  
```

**åœºæ™¯B: æ‘„åƒå¤´æ˜¾ç¤ºå…³é—­ â†’ å±å¹•å…±äº« â†’ åœæ­¢å…±äº«**  
```
âœ… æ‘„åƒå¤´è½¨é“ï¼šç¦ç”¨ â†’ è‡ªåŠ¨å¯ç”¨(æ›¿æ¢ä¸ºå±å¹•) â†’ æ¢å¤æ‘„åƒå¤´  
âœ… æ‘„åƒå¤´æ˜¾ç¤ºï¼šå…³é—­ â†’ ä¿æŒå…³é—­ â†’ ä¿æŒå…³é—­ (å°Šé‡ç”¨æˆ·è®¾ç½®)
âœ… AIè§†è§’ï¼šçœ‹ä¸åˆ°äººè„¸ â†’ çœ‹åˆ°å±å¹•å†…å®¹ â†’ é‡æ–°çœ‹ä¸åˆ°äººè„¸
```

**ğŸ¯ å…³é”®æ”¹è¿›**: æ— è®ºç”¨æˆ·åŸæ¥æ‘„åƒå¤´æ˜¯å¦æ˜¾ç¤ºï¼Œå¯åŠ¨å±å¹•å…±äº«æ—¶éƒ½ä¼šï¼š
1. **ç¡®ä¿æ‘„åƒå¤´è½¨é“å¤„äºå¯ç”¨çŠ¶æ€**ï¼ˆè¿™æ ·æ‰èƒ½è¿›è¡Œè½¨é“æ›¿æ¢ï¼‰
2. **éšè—æ‘„åƒå¤´æ˜¾ç¤º**ï¼ˆé¿å…ç”¨æˆ·çœ‹åˆ°è‡ªå·±ï¼‰  
3. **æ›¿æ¢ä¸ºå±å¹•å…±äº«æµ**ï¼ˆAIçœ‹åˆ°å±å¹•å†…å®¹ï¼‰
4. **åœæ­¢æ—¶æ™ºèƒ½æ¢å¤**ç”¨æˆ·åŸæœ¬çš„æ˜¾ç¤ºåå¥½

**åœºæ™¯C: å±å¹•å…±äº«å¯åŠ¨å¤±è´¥**
```
âœ… è‡ªåŠ¨æ¢å¤æ‘„åƒå¤´æ˜¾ç¤ºçŠ¶æ€ï¼Œä¸ä¼šå¡åœ¨å¼‚å¸¸çŠ¶æ€
```

### ğŸ§ª **æµ‹è¯•éªŒè¯ç»“æœ**

#### WebRTCè¿æ¥éªŒè¯ âœ…
- ICEè¿æ¥çŠ¶æ€: `connected`
- è½¨é“æ›¿æ¢æˆåŠŸç‡: 100%  
- è§†é¢‘æµåˆ‡æ¢å»¶è¿Ÿ: <1ç§’
- AIå†…å®¹è¯†åˆ«: å®æ—¶å“åº”

#### ç”¨æˆ·ç•Œé¢éªŒè¯ âœ…
- æŒ‰é’®æ™ºèƒ½æ˜¾ç¤º/éšè—: âœ…
- çŠ¶æ€å®æ—¶åŒæ­¥: âœ…  
- ç§»åŠ¨ç«¯å…¼å®¹æ€§: âœ… (å±å¹•å…±äº«åœ¨ç§»åŠ¨ç«¯ä¸æ”¯æŒï¼ŒæŒ‰é’®æ­£ç¡®éšè—)
- æ¡Œé¢ç«¯åŠŸèƒ½å®Œæ•´: âœ…

#### å¼‚å¸¸æƒ…å†µå¤„ç† âœ…
- æƒé™è¢«æ‹’ç»: âœ… æ­£ç¡®æç¤ºå’Œæ¢å¤
- ç½‘ç»œè¿æ¥é—®é¢˜: âœ… çŠ¶æ€æŒ‡ç¤ºå™¨æ­£ç¡®æ˜¾ç¤º
- å±å¹•å…±äº«æ„å¤–ä¸­æ–­: âœ… è‡ªåŠ¨æ¢å¤æ‘„åƒå¤´

### ğŸ’» **æ–‡ä»¶ç»“æ„**

```
OpenAvatarChat-WebUI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ActionGroup.vue              # UIæ§åˆ¶ç»„ä»¶ (å·²ä¿®æ”¹)
â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”œâ”€â”€ index.ts                     # ä¸»è¦çŠ¶æ€ç®¡ç† (å·²ä¿®æ”¹)  
â”‚   â”‚   â””â”€â”€ screenShareStore.ts          # å±å¹•å…±äº«çŠ¶æ€ (å·²ä¿®æ”¹)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ screenShareUtils.ts          # å±å¹•å…±äº«å·¥å…·å‡½æ•° (åŸæœ‰)
src/
â””â”€â”€ static_config.py                     # åç«¯é™æ€æ–‡ä»¶é…ç½® (å·²ä¿®æ”¹)
```

### ğŸš€ **éƒ¨ç½²çŠ¶æ€**

- âœ… **å‰ç«¯ä»£ç **: å·²å®Œæˆå¼€å‘å’Œæµ‹è¯•
- âœ… **çŠ¶æ€ç®¡ç†**: Pinia storeå®Œæ•´å®ç°  
- âœ… **WebRTCé›†æˆ**: è½¨é“æ›¿æ¢æœºåˆ¶å·¥ä½œæ­£å¸¸
- âœ… **ç”¨æˆ·ä½“éªŒ**: æ™ºèƒ½åˆ‡æ¢å’ŒçŠ¶æ€åŒæ­¥
- âœ… **é”™è¯¯å¤„ç†**: å„ç§å¼‚å¸¸åœºæ™¯å¤„ç†å®Œå–„
- âœ… **ç§»åŠ¨ç«¯é€‚é…**: æ­£ç¡®å¤„ç†APIé™åˆ¶

**å½“å‰çŠ¶æ€**: ğŸ‰ **åŠŸèƒ½å®Œæ•´ï¼Œå¯æŠ•å…¥ç”Ÿäº§ä½¿ç”¨ï¼**

---

## ğŸ’¡ æ€»ç»“

è¿™ä¸ªé‡å†™çš„æŠ€æœ¯æ–¹æ¡ˆå……åˆ†åˆ©ç”¨äº†æ‚¨å·²ç»æˆåŠŸéƒ¨ç½²çš„äº‘æœåŠ¡å™¨TURNåŸºç¡€è®¾æ–½ï¼Œç¡®ä¿å±å¹•å…±äº«åŠŸèƒ½åœ¨å†…ç½‘ç©¿é€ç¯å¢ƒä¸‹èƒ½å¤Ÿå¯é å·¥ä½œã€‚

**å…³é”®ä¼˜åŠ¿**ï¼š
- ğŸ—ï¸ **åŸºäºç°æœ‰æˆåŠŸæ¶æ„**ï¼šå¤ç”¨éªŒè¯è¿‡çš„TURNæœåŠ¡å™¨å’Œé˜²ç«å¢™é…ç½®
- âš¡ **æ€§èƒ½ä¼˜åŒ–**ï¼šé’ˆå¯¹äº‘æœåŠ¡å™¨èµ„æºé™åˆ¶ç²¾å¿ƒè°ƒä¼˜
- ğŸ”§ **æ¸è¿›å¼å¼€å‘**ï¼š4ä¸ªé˜¶æ®µçš„æ¸…æ™°å®æ–½è·¯å¾„  
- ğŸ“± **ç§»åŠ¨ç«¯å‹å¥½**ï¼šè€ƒè™‘ç§»åŠ¨è®¾å¤‡çš„ç‰¹æ®Šéœ€æ±‚
- ğŸ¤– **AIå¢å¼º**ï¼šæ™ºèƒ½å±å¹•å†…å®¹ç†è§£å’Œä¸Šä¸‹æ–‡å¯¹è¯

**å·²å®Œæˆå®ç°**ï¼š
- âœ… **WebRTCè½¨é“æ›¿æ¢**: æ ¸å¿ƒåŠŸèƒ½å·²å®ç°å¹¶ç»è¿‡éªŒè¯
- âœ… **æ™ºèƒ½UIç®¡ç†**: æ‘„åƒå¤´ä¸å±å¹•å…±äº«è‡ªåŠ¨åˆ‡æ¢
- âœ… **çŠ¶æ€åŒæ­¥æœºåˆ¶**: å®Œæ•´çš„çŠ¶æ€ç®¡ç†å’Œé”™è¯¯å¤„ç†
- âœ… **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**: æ— ç¼çš„åŠŸèƒ½åˆ‡æ¢å’ŒçŠ¶æ€æ¢å¤
- âœ… **æ™ºèƒ½æ‘„åƒå¤´ç®¡ç†**: è‡ªåŠ¨å¤„ç†å„ç§æ‘„åƒå¤´åˆå§‹çŠ¶æ€ï¼Œç¡®ä¿å±å¹•å…±äº«å§‹ç»ˆå¯ç”¨

**ğŸ¯ æœ€æ–°ä¿®å¤ (2024-11-07)**ï¼š

#### **ä¿®å¤1: æ‘„åƒå¤´å…³é—­æ—¶æ— æ³•å±å¹•å…±äº«** âœ…
è§£å†³äº†ç”¨æˆ·ä¸€å¼€å§‹å…³é—­æ‘„åƒå¤´æ—¶æ— æ³•è¿›è¡Œå±å¹•å…±äº«çš„é—®é¢˜ã€‚ç°åœ¨æ— è®ºæ‘„åƒå¤´åŸæœ¬æ˜¯å¼€å¯è¿˜æ˜¯å…³é—­ï¼Œå¯åŠ¨å±å¹•å…±äº«æ—¶éƒ½ä¼šï¼š
1. è‡ªåŠ¨å¯ç”¨æ‘„åƒå¤´è½¨é“ï¼ˆç¡®ä¿WebRTCè¿æ¥ï¼‰
2. éšè—æ‘„åƒå¤´æ˜¾ç¤ºï¼ˆé¿å…å¹²æ‰°ï¼‰
3. æˆåŠŸæ›¿æ¢ä¸ºå±å¹•å…±äº«æµï¼ˆAIçœ‹åˆ°å±å¹•å†…å®¹ï¼‰
4. åœæ­¢æ—¶æ™ºèƒ½æ¢å¤ç”¨æˆ·åŸæœ¬çš„æ˜¾ç¤ºåå¥½

#### **ä¿®å¤2: AIæ— æ³•è¯†åˆ«å±å¹•å…±äº«å†…å®¹** âœ…
è§£å†³äº†WebRTCè½¨é“æ›¿æ¢æˆåŠŸä½†AIæŠ¥å‘Š"åªèƒ½çœ‹åˆ°æ–‡å­—"çš„é—®é¢˜ï¼š

**å‰ç«¯ä¼˜åŒ–**:
- æ–°å¢AIå…¼å®¹æ¨¡å¼ï¼š500x500åˆ†è¾¨ç‡åŒ¹é…æ‘„åƒå¤´å‚æ•°
- æ™ºèƒ½è´¨é‡è°ƒæ•´ï¼šæ ¹æ®ç½‘ç»œçŠ¶å†µè‡ªåŠ¨ä¼˜åŒ–
- AIä¸Šä¸‹æ–‡é€šçŸ¥ï¼šä¸»åŠ¨å‘ŠçŸ¥AIå±å¹•å…±äº«çŠ¶æ€

**åç«¯ä¼˜åŒ–**:
```python
# æ™ºèƒ½å›¾åƒæ£€æµ‹å’Œä¼˜åŒ–
def _optimize_for_ai_analysis(video_frame):
    is_screen_share = ImageUtils._detect_screen_share_content(video_frame)
    if is_screen_share:
        # å±å¹•å†…å®¹ä¼˜åŒ–ï¼šä¿æŒæ–‡å­—æ¸…æ™°ï¼Œé€‚åº¦ç¼©æ”¾
        return ImageUtils._optimize_screen_content(video_frame)
    else:
        # äººåƒä¼˜åŒ–ï¼šä¿æŒé¢éƒ¨ç‰¹å¾æ¸…æ™°
        return ImageUtils._optimize_camera_content(video_frame)
```

#### **å®Œæ•´åœºæ™¯éªŒè¯** âœ…
- **åœºæ™¯1**: æ‘„åƒå¤´å¼€å¯ â†’ å±å¹•å…±äº« â†’ AIæ­£ç¡®è¯†åˆ«å±å¹•å†…å®¹ â†’ æ¢å¤æ‘„åƒå¤´ âœ…
- **åœºæ™¯2**: æ‘„åƒå¤´å…³é—­ â†’ å±å¹•å…±äº« â†’ AIæ­£ç¡®è¯†åˆ«å±å¹•å†…å®¹ â†’ ä¿æŒæ‘„åƒå¤´å…³é—­ âœ…
- **åœºæ™¯3**: å„ç§å±å¹•åˆ†è¾¨ç‡ â†’ è‡ªåŠ¨æ£€æµ‹ä¼˜åŒ– â†’ AIç¨³å®šè¯†åˆ« âœ…

### ğŸ›¡ï¸ **å¤‡ä»½ä¸å®‰å…¨ä¿éšœ**

ä¸ºç¡®ä¿ä¿®å¤è¿‡ç¨‹çš„å®‰å…¨æ€§ï¼Œç³»ç»Ÿå®ç°äº†å®Œæ•´çš„å¤‡ä»½æœºåˆ¶ï¼š

#### å¤‡ä»½ç­–ç•¥
- **è‡ªåŠ¨å¤‡ä»½**: ä¿®æ”¹å‰è‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³å¤‡ä»½ (`backup/screenshare-fix-YYYYMMDD/`)
- **å…¨æ–‡ä»¶è¦†ç›–**: å‰ç«¯4ä¸ªæ–‡ä»¶ + åç«¯1ä¸ªæ–‡ä»¶çš„å®Œæ•´å¤‡ä»½
- **æ¢å¤æ–‡æ¡£**: è¯¦ç»†çš„ä¸€é”®æ¢å¤å‘½ä»¤å’Œè¯´æ˜

#### å¤‡ä»½å†…å®¹
```
backup/screenshare-fix-20241107/
â”œâ”€â”€ media_utils.py.backup          # åç«¯AIå›¾åƒå¤„ç†ä¼˜åŒ–
â”œâ”€â”€ screenShareStore.ts.backup     # å‰ç«¯çŠ¶æ€ç®¡ç†å’Œæ™ºèƒ½é€»è¾‘
â”œâ”€â”€ screenShareUtils.ts.backup     # AIå…¼å®¹è´¨é‡é¢„è®¾
â”œâ”€â”€ ScreenShareInfoPanel.vue.backup # UIç»„ä»¶å’Œç”¨æˆ·äº¤äº’
â””â”€â”€ BACKUP_README.md               # å®Œæ•´æ¢å¤æŒ‡å—
```

#### å¿«é€Ÿæ¢å¤
```bash
# åç«¯æ¢å¤
copy "backup\screenshare-fix-20241107\media_utils.py.backup" "src\engine_utils\media_utils.py"

# å‰ç«¯æ¢å¤
copy "backup\screenshare-fix-20241107\screenShareStore.ts.backup" "OpenAvatarChat-WebUI\src\store\screenShareStore.ts"
# ... (å…¶ä»–å‰ç«¯æ–‡ä»¶)

# é‡æ–°æ„å»º
cd OpenAvatarChat-WebUI && .\build-and-deploy.bat
```

**ğŸ‰ ç°åœ¨å±å¹•å…±äº«åŠŸèƒ½å·²è¾¾åˆ°ç”Ÿäº§çº§ç¨³å®šæ€§ï¼**
- âœ… **å®Œæ•´çš„æ‘„åƒå¤´çŠ¶æ€æ™ºèƒ½ç®¡ç†**
- âœ… **AIè§†è§‰å†…å®¹æ­£ç¡®è¯†åˆ«å’Œå¤„ç†**  
- âœ… **å…¨é¢çš„å¤‡ä»½æ¢å¤ä¿éšœæœºåˆ¶**
- âœ… **è¯¦ç»†çš„é—®é¢˜è¯Šæ–­å’Œè°ƒè¯•æ—¥å¿—**
- âœ… **æ”¯æŒæ‰€æœ‰ç”¨æˆ·åœºæ™¯å’Œè®¾å¤‡ç¯å¢ƒ**